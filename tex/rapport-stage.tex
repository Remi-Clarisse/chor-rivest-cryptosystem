\documentclass[a4paper, titlepage, 11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[francais]{babel}
\usepackage{amsmath, amsthm, amssymb, mathabx}
\usepackage{tikz}
\usepackage{algorithm, algorithmic}
\usepackage{array, booktabs}
\usepackage{cite}
\usepackage{hyperref}
\hypersetup{
     colorlinks   = true,
     citecolor    = magenta,
     linkcolor    = cyan,
     linktoc      = page
}
\usepackage[top=3cm, bottom=3cm, left=3cm, right=3cm]{geometry}
\allowdisplaybreaks

\newtheorem{theo}{Théorème}[section]
\newtheorem{lemm}[theo]{Lemme}
\newtheorem{prop}[theo]{Proposition}
\newtheorem{coro}[theo]{Corollaire}
\theoremstyle{definition}
\newtheorem{defi}[theo]{Définition}
\theoremstyle{remark}
\newtheorem{rema}[theo]{Remarque}
\newtheorem{exem}[theo]{Exemple}
\newtheorem{appl}[theo]{Application}
\newtheorem{heur}[theo]{Heuristique}


\def\N{\mathbb N}
\def\A{\mathbb A}
\def\Z{\mathbb Z}
\def\Q{\mathbb Q}
\def\R{\mathbb R}
\def\C{\mathbb C}
\def\K{\mathbb K}
\def\F{\mathbb F}
\def\O{O}
\def\o{o}
\def\gf #1{\mathbb{F}_{#1}}
\def\frob{\operatorname{Frob}}
\def\card{\operatorname{Card}}
\def\car{\operatorname{car}}
\def\pgcd{\operatorname{pgcd}}
\def\ppcm{\operatorname{ppcm}}
\def\id{\operatorname{id}}
\def\aut{\operatorname{Aut}}
\def\hom{\operatorname{Hom}}
\def\isom{\operatorname{Isom}}
\def\gal{\operatorname{Gal}}
\def\mbf #1{\mathbf{#1}}
\def\NP{\mathbb{NP}}
\def\gen #1{\left\langle#1\right\rangle}
\def\ceil #1{\left\lceil#1\right\rceil}
\def\floor #1{\left\lfloor#1\right\rfloor}

\newcommand{\extension}[2]{{#1} / {#2}} % #1 grand corps et #2 petit corps

\floatname{algorithm}{Algorithme}
\renewcommand{\algorithmicrequire}{\textbf{Entrée :}}
\renewcommand{\algorithmicensure}{\textbf{Sortie :}}
\renewcommand{\algorithmicend}{\textbf{fin}}
\renewcommand{\algorithmicif}{\textbf{si}}
\renewcommand{\algorithmicthen}{\textbf{alors}}
\renewcommand{\algorithmicelse}{\textbf{sinon}}
\renewcommand{\algorithmicfor}{\textbf{pour}}
\renewcommand{\algorithmicforall}{\textbf{pour tout}}
\renewcommand{\algorithmicdo}{\textbf{faire}}
\renewcommand{\algorithmicwhile}{\textbf{tant que}}
\renewcommand{\algorithmicloop}{\textbf{boucle}}
\renewcommand{\algorithmicrepeat}{\textbf{repéter}}
\renewcommand{\algorithmicuntil}{\textbf{jusqu'à}}
\renewcommand{\algorithmicprint}{\textbf{afficher}}
\renewcommand{\algorithmicreturn}{\textbf{retourner}}
\renewcommand{\algorithmictrue}{\textbf{vrai}}
\renewcommand{\algorithmicfalse}{\textbf{faux}}

\title{\'Etude du cryptosystème de Chor-Rivest}
\author{Rémi {\sc Clarisse}}
\date{Mai-Août 2017}

\begin{document}
\thispagestyle{empty}
\centerline{\includegraphics[width=8cm,height=25mm]{logo-bordeaux.png} \hspace{2cm} \includegraphics[width=8cm,height=25mm]{logo-inria.png}}

\vspace{2cm}

\centerline{\large\bfseries Master 1 de Cryptologie et Sécurité Informatique}
\centerline{\large\bfseries \'Equipe-projet Grace}
\centerline{\rule{5cm}{2pt}}
\centerline{\bfseries Stage estival 2017}


\begin{center}
\vspace{3cm}

{\Huge\bfseries Rapport de stage \\}
\vspace{0.15cm}\centerline{\rule{10cm}{0.5pt}}\vspace{0.15cm}
{\LARGE\bfseries \'Etude du cryptosystème de Chor-Rivest}
 \vspace{4cm}

{\large Rémi {\sc Clarisse}}

\vspace{6.5cm}

{\large Tuteurs: Daniel {\sc Augot} et Luca {\sc De Feo}}
\end{center}
\newpage
\thispagestyle{empty}
\section*{Introduction}

Du 15 mai au 31 août 2017, j'ai intégré en tant que stagiaire l'équipe Grace de Inria Saclay--Île-de-France. Sous la supervision de Daniel Augot, responsable de l'équipe, et Luca De Feo, chercheur délégué, j'ai étudié le cryptosystème présenté par Benny Chor et Ronald Rivest~\cite{chorRivest1988} en 1984, ainsi que l'algorithme qu'Antoine Joux~\cite{joux2013} a conçu en 2013 pour le calcul de logarithme discret dans un corps fini de petite caractéristique.

Le cryptosystème de Chor-Rivest est un cryptosytème asymétrique qui base sa sécurité sur un problème de sac à dos. Cependant, pour produire la clé publique, il faut avoir recours à des calculs de logarithmes discrets dans un corps fini $\gf{p^h}$. C'est pour cela que Chor et Rivest incitent l'utilisateur à prendre des paramètres facilitant la résolution du problème du logarithme discret, en sélectionnant par exemple un exposant $h$ composé. C'est justement ce pré-requis qui a permis à Serge Vaudenay en 2000 de confectionner une cryptanalyse \cite{vaudenay2000}, qui le fait arriver à la conclusion qu'il faut choisir un exposant $h$ premier.

Nous retrouvons donc avec deux choix: l'un facilitant le calcul de logarithmes pour fabriquer les clés et l'autre rendant le cryptosystème résistant à la meilleure cryptanalyse existante à ce jour. Il est clair qu'avoir un cryptosystème cassé est inutile. C'est pour cela que nous nous intéressons à l'algorithme de Joux, en espérant qu'il nous permette de franchir l’obstacle du calcul de logarithmes.

Le rapport est organisé comme suit: en section~\ref{sec:presInria}, nous présentons Inria, ainsi que l'équipe-projet Grace, et faisons un bref descriptif des attentes du stage. Nous évoquons les méthodes classiques de calcul de logarithme dans des groupes cycliques en section~\ref{sec:DLPgroupe}. Les sections~\ref{sec:cryptosysteme} et~\ref{sec:cryptanalyse} exposent les travaux déjà effectués sur le cryptosysème de Chor-Rivest et la cryptanalyse de Vaudenay. La section~\ref{sec:DLPJoux} donne divers résultats sur le calcul de logarithmes discrets dans des corps finis et aborde le papier de Joux, dont nous espérons en déduire, en section~\ref{sec:consequences}, des améliorations possibles pour le cryptosystème de Chor-Rivest.

\paragraph{GitHub.} Des fichiers comportant les divers algorithmes sont présents sur GitHub pour agrémenter la lecture du rapport. Il y a une implantation élémentaire en \verb|C| de l'algorithme rho de Pollard \cite{pollard1978} dans un corps $\gf{p}$, où $p$ est un nombre premier inférieur à $2^{32}$, ainsi que d'autres fichiers en SageMath implantant le cryptosystème de Chor-Rivest \cite{chorRivest1988}, l'attaque de Serge Vaudenay \cite{vaudenay2000} et une variante de l'algorithme d'Antoine Joux \cite{joux2013}, exposés en section \ref{sec:cryptosysteme}, \ref{sec:cryptanalyse} et \ref{sec:DLPJoux} respectivement. Il est laissé au lecteur l'initiative d'explorer le dépôt.
\paragraph{URL.}\url{https://github.com/Remi-Clarisse/chor-rivest-cryptosystem.git}

\setcounter{tocdepth}{1}
\tableofcontents

\newpage

\section{La présentation de Inria}\label{sec:presInria}

Inria (Institut National de Recherche en Informatique et en Automatique) emploie 2\;600 collaborateurs issus de diverses universités mondiales, qui relèvent les défis des sciences informatiques et mathématiques. Inria est organisé en \og{}équipes-projets\fg{} qui rassemblent des chercheurs aux compétences complémentaires autour d’un projet scientifique focalisé. Ce modèle ouvert et agile lui permet d’explorer des voies originales avec ses partenaires industriels et académiques. Inria répond ainsi aux enjeux pluridisciplinaires et applicatifs de la transition numérique. À l'origine de nombreuses innovations créatrices de valeur et d'emploi, Inria transfère vers les entreprises (start-up, PME et grands groupes) ses résultats et ses compétences, dans des domaines tels que la santé, les transports, l'énergie, la communication, la sécurité et la protection de la vie privée, la ville intelligente, l’usine du futur\dots

\paragraph{Source.} \url{https://www.inria.fr/}

\subsection{Centre Inria Saclay--Île-de-France}

À Paris-Saclay, Inria développe des recherches à fort impact sociétal pour inventer le monde de demain. Créé en 2008, le centre de recherche Inria Saclay - Île-de-France accueille 450 scientifiques et 100 membres des services d’appui à la recherche. Les scientifiques sont organisés en 31 équipes de recherche dont 26 sont communes avec des partenaires du plateau de Saclay. Le centre accueille également le Joint Lab Inria / Microsoft Research.

\textit{\og{}Le centre Inria Saclay--Île-de-France est un acteur essentiel de la recherche en sciences du numérique sur le plateau de Saclay. Il porte les valeurs et les projets qui font l’originalité d’Inria dans le paysage de la recherche: l’excellence scientifique, le transfert technologique, les partenariats pluridisciplinaires avec des établissements aux compétences complémentaires aux nôtres, afin de maximiser l’impact scientifique, économique et sociétal d’Inria.\fg{}} \\
--- Bertrand Braunschweig, directeur du centre Inria Saclay - Île-de-France.

\paragraph{Source.} \url{https://www.inria.fr/centre/saclay/}

\subsection{Équipe-projet Grace}
Voici la description publique de l'équipe-projet Grace (Geometry, aRithmetic, Algorithms, Codes and Encryption): \og{}La théorie algorithmique des nombres et les problèmes computationnels associés aux courbes algébriques sur les corps, les anneaux, sont centraux dans notre thème de recherche. Ce domaine très riche des mathématiques et de l'informatique a déjà montré son importance dans la cryptographie à clé publique, avec des succès industriels comme le système RSA et la cryptographie à base de courbes elliptiques. Il est moins connu que de bons codes correcteurs d'erreur ou autres peuvent être construits avec les mêmes objets mathématiques, qui sont aussi au c\oe ur de Grace. Nous pensons qu'une interprétation géométrique et unifiée donne une vue profonde sur la nature et les performances des ces problèmes en théorie des codes et cryptographie. Ces deux domaines d'applications interviennent pour la fiabilité et la sécurité des applications. Alors que la cryptologie est traditionnellement au c\oe ur de l'informatique, ce n'est que plus récemment que la théorie des codes y trouve des applications, en sortant du document des télécommunications.\fg{}

L'équipe Grace est en partenariat avec le CNRS et l'École polytechnique, et en collaboration avec le Laboratoire Informatique de l'École polytechnique (LIX).
L'équipe est composée de dix membres. Outre Daniel Augot, le responsable, il y a quatre membres permanents: Alain Couvreur, Françoise Levy-dit-Vehel, François Morain et Benjamin Smith. Les cinq autres membres sont Luca De Feo, chercheur délégué, Nicholas Coxon et William George, post-doctorants, et Élise Barelli et Julien Lavauzelle, en dernière année de thèse.
Et n'oublions pas leur fabuleuse assistante, Jessica Gameiro!
Aussi, au moment de la rédaction de ces lignes, nous sommes trois stagiaires avec Benoît Billaudel et Jean Kieffer.

\paragraph{Sources.} \url{https://www.inria.fr/equipes/grace/} et \url{https://team.inria.fr/grace/}

\subsection{Attentes du stage}

Les objectifs du stage donnés par Daniel et Luca sont:\begin{enumerate}
\item comprendre le cryptosystème de Chor-Rivest,
\item l'implanter en SageMath selon la proposition d'origine,
\item et si le temps le permet, implanter une version modifiée, qui utilise des extensions d'extensions de corps.
\end{enumerate}
Les deux premiers points sont traités dans la section~\ref{sec:cryptosysteme}, les codes SageMath étant sur le {GitHub}. Quant au troisième point, il convient d'expliquer pourquoi nous souhaitons implanter une version modifiée. Le cryptosytème de Chor-Rivest \cite{chorRivest1988} est réputé \og{}cassé \fg{} par Serge Vaudenay \cite{vaudenay2000}, ce que nous détaillons en section \ref{sec:cryptanalyse}. Cependant, la cryptanalyse s’appuie sur ce que l'on pourrait appeler une particularité du système: la fabrication de la clé publique requiert que l'on se place dans un corps fini dans lequel le calcul de logarithme discret n'est pas rédhibitoire. Cette exigence est satisfaite en particulier lorsque le corps fini considéré a de nombreux sous-corps, ce qui est d'ailleurs le choix préconisé par Benny Chor et Ronald Rivest. Donc, une façon efficace de rendre impraticable l'attaque de Vaudenay est de choisir un corps fini ayant pour seuls sous-corps lui-même et son sous-corps premier. Cela rend par conséquence le calcul classique de logarithme discret difficile\footnote{On entend par \og{}calcul classique\fg{} le calcul par des algorithmes ne s'aidant pas de la structure de corps sous-jacente au groupe.}. Il nous faut donc nous pencher plus sérieusement sur le problème du calcul de logarithme discret dans les corps finis, ce que nous faisons dans la section~\ref{sec:DLPJoux}, en étudiant notamment l'algorithme d'Antoine Joux~\cite{joux2013}.

L'outil de calcul utilisé est SageMath, version 7.5.1.

\section{Le problème du calcul de logarithme discret}\label{sec:DLPgroupe}

Avant de commencer, nous pensons qu'il est préférable d'introduire les algorithmes classiques de calcul de logarithme tels que Pohlig-Hellman~\cite{pohligHellman1978}, pas de bébé -- pas de géant et rho de Pollard~\cite{pollard1978}. Ils sont classiques dans le sens où ils opèrent dans des groupes, sans tenir compte d'une possible structure supplémentaire.
Les résultats donnés ici sont essentiellement tous issus du manuel de Steven Galbraith \cite[section 13 et 14, p. 246 à 297]{galbraith2012}.

\begin{defi}\label{defLogDiscret}
Soit $G$ un groupe noté multiplicativement. Le \textit{problème du logarithme discret} est : étant donné $g\in G$ et $h \in \gen{g}$, le sous-groupe engendré par $g$, trouver l'entier $a$, tel que $h=g^a$. Nous notons alors $a=\log_g(h)$, et $g$ est appelé la \textit{base} du logarithme $a$.\end{defi}

\subsection{Recherche exhaustive}

Soient $G$ un groupe, $g\in G$ et $h \in \gen{g}$. La façon la plus simple de résoudre le problème du logarithme discret est de calculer à la suite les $g^a$ pour $0 \leqslant a < n$, où $n$ est l'ordre de $g$, et de comparer la valeur obtenue avec $h$. Cela s'effectue en au plus $n - 2$ opérations dans le groupe et $n$ comparaisons. Cet algorithme naïf, donné par l'algorithme~\ref{algo:logDiscretNaif}, a une complexité en $\O(n)$.

\begin{algorithm}[h]
\caption{Algorithme de recherche exhaustive}
\label{algo:logDiscretNaif}
\begin{algorithmic}[1]
\REQUIRE{$g$ et $h \in \gen{g}$}
\ENSURE{$a$ tel que $g^a = h$ et $1 \leqslant a \leqslant n$}
\STATE{$a\gets 1$}
\STATE{$t\gets g$}
\WHILE{$t \neq h$}
	\STATE{$a\gets a + 1$}
	\STATE{$t\gets tg$}
\ENDWHILE
\RETURN{$a$}
\end{algorithmic}
\end{algorithm}

\subsection{Méthode de Pohlig et Hellman}
\label{s-sec:pohligHellman}
Soient $G$ un groupe, $g\in G$ et $h \in \gen{g}$. Supposons que $g$ est d'ordre $n$. \'Ecrivons $$n = \prod_{i=1}^r p_i^{\alpha_i},$$
où les $p_i$ sont premiers et les $\alpha_i$ sont tels que $p_i$ ne divise pas $n/p_i^{\alpha_i}$.
L'idée de la méthode de Stephen Pohlig et Martin Hellman \cite{pohligHellman1978} est de calculer $a$ modulo les puissances de nombre premier $p_i^{\alpha_i}$ et de recouvrer le logarithme en utilisant le théorème des restes chinois.

Pour cela, nous utilisons l'homomorphisme de groupes du lemme suivant, qui permet de réduire la recherche du logarithme discret aux sous-groupes d'ordre une puissance de nombre premier.

\begin{lemm}
Soient $G$ un groupe cyclique d'ordre $n$, $g$ un générateur de $G$, i.e. $G = \gen{g}$, et $q$ un diviseur de $n$. L'application $\varphi_q : x \mapsto x^{n/q}$ est un homomorphisme de groupes de $G$ dans l'unique sous-groupe de $G$ d'ordre $q$. Ainsi, si $h = g^a$, alors $$\varphi_q(h) = \varphi_q(g)^{a \bmod{q}}.$$
\end{lemm}

Dans les sous-groupes cycliques d'ordre une puissance de nombre premier, voici comment nous pouvons procéder : supposons que $g_0$ est d'ordre $p^\alpha$ et que $h_0 := g_0^a$, pour un entier. Nous pouvons écrire $a = a_0 + a_1 p + \cdots + a_{\alpha-1}p^{\alpha-1}$, où les $a_i$ sont tels que $0\leqslant a_i < p$. Soit $g_1 := g_0^{p^{\alpha-1}}$. \'Elever à la puissance $p^{\alpha-1}$ donne :
$$h_0^{p^{\alpha-1}} = {(g_0^a)}^{p^{\alpha-1}} = {\left(g_0^{p^{\alpha-1}}\right)}^{a_0 + a_1 p + \cdots + a_{\alpha-1}p^{\alpha-1}} = \prod_{i=0}^{\alpha -1 } g^{a_ip^{\alpha-1+i}} = g_1^{a_0}.$$
Nous pouvons ensuite déterminer $a_0$, en cherchant de manière exhaustive ou avec une autre méthode, comme pas de bébé -- pas de géant (\ref{s-sec:BSGS}) ou rho de Pollard (\ref{s-sec:rho}).
Pour avoir $a_1$, définissons $h_1 := h_0g_0^{-a_0}$ de sorte que
$$h_1 = g_0^{a_1 p + \cdots + a_{\alpha-1}p^{\alpha-1}}.$$
Puis, en élevant à la puissance $p^{\alpha-2}$ :
$$h_1^{p^{\alpha-2}} = g_1^{a_1}.$$
Pour obtenir $a_2$, nous posons $h_2 := h_1g_0^{-a_1p}$, et ainsi de suite pour les autres valeurs. Cela donne la solution modulo $p^\alpha$.
Une fois que $a$ est connu pour tout $p^\alpha$ divisant $n$, nous pouvons reconstituer $a$ à l'aide du théorème des restes chinois.

\begin{algorithm}[h]
\caption{Méthode de Pohlig-Hellman}
\label{algo:pohligHellman}
\begin{algorithmic}[1]
\REQUIRE{$g$ d'ordre $n$, $h \in \gen{g}$ et ${(p_i,\alpha_i)}_{1\leqslant i \leqslant r}$ tel que $n = \prod p_i^{\alpha_i}$}
\ENSURE{$a$ tel que $g^a = h$}
\FOR{$i$ allant de $1$ à $r$}
	\STATE{$a_i \gets 0$}
	\STATE{$g_0 \gets g^{n/p_i}$}
	\FOR{$j$ allant de $1$ à $\alpha_i$}
		\STATE{$h_0 \gets g^{-a_in/p_i^j}h^{n/p_i^j}$}
		\STATE{$b \gets \verb|log_in_sub_grp|(h_0,g_0)$}
		\STATE{$a_i \gets a_i + b p_i^{j-1}$}
	\ENDFOR
\ENDFOR
\STATE{calculer $a \equiv a_i \pmod{p_i^{\alpha_i}}$, pour $1\leqslant i \leqslant r$, grâce au théorème des restes chinois}
\RETURN{$a$}
\end{algorithmic}
\end{algorithm}

L'algorithme~\ref{algo:pohligHellman} met en \oe uvre la méthode de Pohlig-Hellman, où le calcul de logarithme dans les sous-groupes est laissé à choisir par la fonction \verb|log_in_sub_grp|.

\begin{defi} Un entier est dit \textit{$B$-friable} si tous ses diviseurs premiers sont inférieurs ou égaux à $B$.
\end{defi}

\begin{theo}\label{theo:pohligHellman}
Soit $g \in G$ d'ordre $n$. Soit $B\in\N$ tel que $n$ est $B$-friable. Alors l'algorithme de Pohlig-Hellman (\ref{algo:pohligHellman}) résout le problème du logarithme discret en $\O(\log(n)^2 + B\log(n))$ opérations dans le groupe si \verb|log_in_sub_gpr| est la recherche exhaustive (algorithme~\ref{algo:logDiscretNaif}) et en $\O(\log(n)^2 + \sqrt{B}\log(n)/\log(B))$ opérations dans le groupe si \verb|log_in_sub_gpr| est l'algorithme pas de bébé -- pas de géant (algorithme~\ref{algo:BSGS}).
\end{theo}

\`A cause de cette méthode, les nombres $B$-friables, pour un petit $B$, ne rendent pas de façon significative la recherche de logarithmes discrets plus difficile. Donc, en général, en cryptographie, il est préférable d'utiliser des éléments d'ordre un grand nombre premier.

\subsection{Algorithme pas de bébé -- pas de géant}
\label{s-sec:BSGS}

Cet algorithme, souvent attribué à Daniel Shanks, est un incarnation du principe de \textit{time/memory tradeoff}, i.e. faire un compromis entre l'espace utilisé en mémoire et le temps d'exécution. Supposons $g$ d'ordre un nombre premier $p$ et $h = g^a$ pour un certain $0 \leqslant a < p$. Soit $m := \ceil{\sqrt{p}}$. Il existe alors deux entiers $a_0$ et $a_1$ tels que $a = a_0 + a_1m$ et $0 \leqslant a_0, a_1 < m$. Il s'en suit :
$$g^{a_0} = h\cdot{(g^{-m})}^{a_1},$$
et cette observation mène à l'algorithme~\ref{algo:BSGS}.

Cependant, l'utilisation importante de l'espace mémoire pour les valeurs calculées par l'algorithme pas de bébé -- pas de géant devient rapidement prohibitif, car il requiert $\O(\sqrt{p}\log(p))$ bits de stockage (si les éléments du groupe sont représentables en mémoire en $\O(\log(p))$ bits).

\begin{algorithm}[h]
\caption{Algorithme pas de bébé -- pas de géant}
\label{algo:BSGS}
\begin{algorithmic}[1]
\REQUIRE $g$ d'ordre $p$ et $h \in \gen{g}$
\ENSURE $a$ tel que $g^a = h$
\STATE{$m \gets \ceil{\sqrt{p}}$}
\STATE{$L$ une liste vide}
\STATE{$x \gets 1$}
\FOR[Calcul et stockage des pas de bébé]{$i$ allant de $0$ à $m$}
	\STATE{$L \gets L + [x, i]$}
	\STATE{$x \gets xg$}
\ENDFOR
\STATE{$u \gets g^{-m}$}
\STATE{$y \gets h$}
\STATE{$j \gets 0$}
\WHILE[Calcul des pas de géant]{$[y, \ast] \not \in L$}
	\STATE{$y\gets yu$}
	\STATE{$j\gets j+1$}
\ENDWHILE
\STATE{trouver $[x,i] \in L$ tel que $x=y$}
\RETURN{$i+mj$}
\end{algorithmic}
\end{algorithm}

\begin{theo}
Soit $G$ d'ordre $p$. Si les éléments du groupe sont représentables en mémoire en $\O(\log(p))$ bits et si les opérations dans le groupe se font en $\O(\log(p)^2)$ opérations binaires, alors l'algorithme pas de bébé -- pas de géant (\ref{algo:BSGS}) résout le problème du logarithme discret en $\O(\sqrt{p}\log(p)^2)$ opérations binaires et $\O(\sqrt{p}\log(p))$ bits de stockage.
\end{theo}

\subsection{La méthode rho de Pollard}\label{s-sec:rho}

Après une introduction, nous expliquons le fonctionnement de la méthode rho de Pollard, qui a été conçue en 1978 par John Michael Pollard \cite{pollard1978}.
L'exposé suivant suit, le plus simplement possible, celui fait par Galbraith~\cite[section 14, p. 264]{galbraith2012}\footnote{\`A consulter pour les démonstrations et pour plus de détails.}.

La méthode de Pollard se sert du théorème suivant, plus connu sous le nom du paradoxe des anniversaires:
\begin{theo}\label{paradoxeAnniversaire}
Soit $\mathcal S$ un ensemble à $n$ éléments. Si les éléments sont tirés de façon uniformément aléatoire de $\mathcal S$, alors le nombre attendu d'éléments à tirer avant d'avoir un tirage identique à un précédent est moins de $\sqrt{\pi n /2} + 2$.
\end{theo}

\subsubsection{Discussion liminaire : partitionner, marcher, chercher}

\paragraph{Introduction.}La méthode rho permet, avec une forte probabilité, de résoudre le problème du logarithme discret dans un groupe abélien. Elle se base sur des marches aléatoires : elle définit donc un algorithme non-déterministe, i.e. sur une même entrée, chaque exécution de l'algorithme peut être différente, l'issue étant la même.

 Soient $G := \gen{g}$ d'ordre un nombre premier $p$ et $h = g^a$ pour un certain $0 \leqslant a < p$.

\paragraph{Idée.} Observons que si nous trouvons $a_i$, $b_i$, $a_j$ et $b_j$ dans $\Z/p\Z$ tels que :
$$ g^{a_i}h^{b_i} = g^{a_j}h^{b_j},$$
et $b_i \not\equiv b_j \pmod{p}$, alors nous pouvons résoudre le problème du logarithme discret comme suit : $$h = g^{(a_i-a_j)(b_j-b_i)^{-1}\bmod{p}}.$$

\paragraph{Marche pseudo-aléatoire.} Pollard \cite{pollard1978} s'est inspiré de la théorie des marches aléatoires et a pensé à construire une suite pseudo-aléatoire $x_i = g^{a_i}h^{b_i}$ d'éléments de $G$ par itération d'une fonction convenable $f:G \rightarrow  G$, appelée \textit{fonction d'itération}. En d'autres termes, il choisit une valeur de départ $x_1$ et définit le reste de la suite par $x_{i+1}=f({x_i})$, pour $i \geqslant 1$. Une telle suite $x_1, x_2, \dots$ est appelée une \textit{marche pseudo-aléatoire déterministe}.

\paragraph{Pré-période et période.}Comme $G$ est fini, cette suite est \textit{ultimement périodique} : il existe deux entiers $\lambda \geqslant 1$ et $\mu \geqslant 0$ tels que les éléments $x_1, x_2, \dots, x_{\lambda + \mu -1}$ soient distincts deux à deux et $x_{k} = x_{\lambda + k}$ pour tout $k\geqslant \mu$. Nous appelons $\mu$ la \textit{pré-période de la suite} et $\lambda$ la \textit{période de la suite}. Sous l'hypothèse que $x_1$ soit choisi dans $G$ aléatoirement selon la distribution uniforme, et que $f$ est une fonction aléatoire, la valeur attendue de $\lambda$ et $\mu$ est proche de:
$$\sqrt{\frac{\pi p}{8}} \approx 0.627 \sqrt{p}.$$

\paragraph{Collision.} Une paire $(x_i, x_j)$ est appelée \textit{collision} si $x_i = x_j$ et $1 \leqslant i < j$. Si les éléments dans la marche sont choisis uniformément et indépendants dans $G$, alors par le paradoxe des anniversaires (théorème~\ref{paradoxeAnniversaire}), la valeur attendue pour $j$ est:
$$\sqrt{\frac{\pi p}{2}} \approx 1.253 \sqrt{p}.$$

\paragraph{Rho.} L'image obtenue en \og{}dessinant\fg{} les termes de la suite ${(x_i)}_{i\geqslant 1}$, en commençant en bas et finissant par le cycle en haut, forme la lettre grecque $\rho$. Ainsi, une méthode utilisant une telle suite s'appelle une \textit{méthode rho}.

\begin{figure}[h]\caption{Illustration de la forme $\rho$ de la suite}
\begin{center}
\begin{tikzpicture}

\coordinate (head0) at (0,-3) ;
\coordinate (head1) at (-.4,-2.2) ;
\coordinate (head2) at (-.6,-1) ;
\coordinate (head3) at (-.2,.1) ;
\coordinate (head4) at (.4,1) ;
\coordinate (head5) at (1.2,1.6) ;
\coordinate (tail0) at (3-1,1+1) ;
\coordinate (tail1) at (3,1+1.414) ;
\coordinate (tail2) at (3+1,1+1) ;
\coordinate (tail3) at (3+1.414,1) ;
\coordinate (tail4) at (3+1,1-1) ;
\coordinate (tail5) at (3,1-1.414) ;
\coordinate (tail6) at (3-1,1-1) ;
\coordinate (tail7) at (3-1.414,1) ;
\draw[thick] (head0) -- (head1) -- (head2) -- (head3) -- (head4) -- (head5) -- (tail0) -- (tail1) -- (tail2) -- (tail3) -- (tail4) -- (tail5) -- (tail6) -- (tail7) -- (tail0) ;
\draw[thin, ->, >= stealth] (3,2) arc (90:-230:1) ;
\draw[thin, >= stealth] (.5,-3) edge[out=135,in=210, ->] (1.2,1.1) ;
\draw (head0) node {$\bullet$};
\draw (head1) node {$\bullet$};
\draw (head2) node {$\bullet$};
\draw (head3) node {$\bullet$};
\draw (head4) node {$\bullet$};
\draw (head5) node {$\bullet$};
\draw (tail0) node {$\bullet$};
\draw (tail1) node {$\bullet$};
\draw (tail2) node {$\bullet$};
\draw (tail3) node {$\bullet$};
\draw (tail4) node {$\bullet$};
\draw (tail5) node {$\bullet$};
\draw (tail6) node {$\bullet$};
\draw (tail7) node {$\bullet$};

\end{tikzpicture}

\end{center}
\end{figure}

\paragraph{Partition.} Pour simuler une fonction aléatoire, i.e. la fonction d'itération, de $G$ dans lui-même, il est pratique de commencer par partitionner $G$ en $n$ ensembles (d’à peu près la même taille), de sorte que $G = \mathcal{S}_0 \cup  \mathcal{S}_1 \cup \dots \cup \mathcal{S}_{n-1}$. Les ensembles $\mathcal{S}_i$ sont définis en utilisant une \textit{fonction de sélection}: $$s : G \rightarrow \{0, \dots, n-1 \},$$ par $\mathcal{S}_i = \{\alpha \in G : s(\alpha) = i\}$.

\paragraph{Résumé.} Les trois ingrédients principaux d'une méthode rho sont : une partition de $G$ grâce à une fonction de sélection, une suite ${(x_i)}_{i\geqslant 1}$ à l'aspect aléatoire construite grâce à une fonction d'itération et à la partition précédente\footnote{La fonction d'itération a autant de règles que le cardinal de la partition.}, et un algorithme pour chercher la collision dans la suite ${(x_i)}_{i\geqslant 1}$.

\subsubsection{Partition du groupe: fonction de sélection}

Des choix pertinents pour la fonction de sélection $s : G \rightarrow \{0, \dots, n-1 \}$ sont donnés dans les papiers de Teske \cite{teske2001} et de Bai et Brent \cite{bai2008}. Cependant, donnons pour exemple une fonction de sélection, qui en pratique n'est pas \og{}suffisamment aléatoire\fg{}. Supposons que l'implantation du groupe $G$ permette de représenter chaque élément $g$ de $G$ de façon unique comme une chaîne binaire $\mbf b(g)$. Alors, en considérant $\mbf b(g)$ comme un entier, nous pouvons prendre: $s(g) = \mbf b(g) \pmod{n}$.

\subsubsection{Définition de la suite: fonction d'itération}

Pour commencer, associons à chaque élément de la partition un élément du groupe: soient $g_j = g^{u_j}h^{v_j}$ pour $0 \leqslant j \leqslant n -1$, où $ 0\leqslant u_j, v_j < p$ sont choisis de façon uniformément aléatoire. Puis, posons comme premier terme de la suite $x_1 := g$. La suite est ensuite définie par la relation $x_{i+1} = f(x_i)$, où $f$ est une fonction d'itération. Par exemple, on peut prendre pour $f$:
\begin{equation}\label{eqn:rhoOriginal}
x_{i+1} = f(x_i) = \left\{ \begin{array}{l l}
x_i^2 & \text{si } s(x_i) = 0,\\
x_ig_j & \text{si } s(x_i) = j, \quad 1 \leqslant j \leqslant n-1,
\end{array} \right.
\end{equation}
ou bien,
\begin{equation}\label{eqn:rhoAdditive}
x_{i+1} = f(x_i) = x_ig_{s(x_i)}.
\end{equation}

\begin{rema}
Une fois la fonction de sélection $s$ et les valeurs de $u_j$ et $v_j$ choisies, la marche est déterministe.
\end{rema}

Il est nécessaire de garder trace de la décomposition $x_i = g^{a_i}h^{b_i}$.
Pour la suite définie grâce à (\ref{eqn:rhoOriginal}), les valeurs $a_i, b_i \in \Z/p\Z$ sont obtenues en posant $a_1 = 1$, $b_1 = 0$ et mettant à jour:
$$a_{i+1} = \left\{\begin{array}{l l}
2a_i \pmod{p} & \text{si } s(x_i) = 0, \\
a_i + u_{s(x_i)} \pmod{p} & \text{si } s(x_i) > 0, \\
\end{array}\right.$$
$$b_{i+1} = \left\{\begin{array}{l l}
2b_i \pmod{p} & \text{si } s(x_i) = 0, \\
b_i + v_{s(x_i)} \pmod{p} & \text{si } s(x_i) > 0. \\
\end{array}\right.$$
Alors que pour la suite définie grâce à (\ref{eqn:rhoAdditive}), les valeurs $a_i, b_i \in \Z/p\Z$ sont obtenues en posant $a_1 = 1$, $b_1 = 0$ et mettant à jour:
$$a_{i+1} = a_i + u_{s(x_i)} \pmod{p}, $$
$$b_{i+1} = b_i + v_{s(x_i)} \pmod{p}.$$

\subsubsection{Recherche de collision: algorithme de Floyd}

Pour trouver une collision dans la suite ${(x_i)}_{i\geqslant 1}$, Pollard utilise l'\textit{algorithme de recherche de cycle de Floyd}, aussi appelé l'\textit{algorithme du lièvre et de la tortue}.
Cet algorithme compare $x_i$ et $x_{2i}$, et donne une collision $(x_i, x_{2i})$, pour $i \geqslant 1$. Le plus petit $i$ tel que $x_i = x_{2i}$ est appelé l'\textit{épacte}.
Notons $\mu$ la pré-période de la suite et $\lambda$ la période de la suite.

\begin{prop}\label{prop:floyd}
En gardant les notations précédentes, $x_{2i} = x_i$ si, et seulement si, $\lambda$ divise $i$ et $i \geqslant \mu$. En outre, il existe un $\mu \leqslant i < \mu + \lambda$ tel que $x_{2i} = x_i$.
\end{prop}

\begin{figure}[h]\caption{Illustration de l'algorithme du lièvre (rouge) et de la tortue (verte)}
\begin{center}
\begin{tikzpicture}

\coordinate (head0) at (0,-3) ;
\coordinate (head1) at (-.4,-2.2) ;
\coordinate (head2) at (-.6,-1) ;
\coordinate (head3) at (-.2,.1) ;
\coordinate (head4) at (.4,1) ;
\coordinate (head5) at (1.2,1.6) ;
\coordinate (tail0) at (3-1,1+1) ;
\coordinate (tail1) at (3,1+1.414) ;
\coordinate (tail2) at (3+1,1+1) ;
\coordinate (tail3) at (3+1.414,1) ;
\coordinate (tail4) at (3+1,1-1) ;
\coordinate (tail5) at (3,1-1.414) ;
\coordinate (tail6) at (3-1,1-1) ;
\coordinate (tail7) at (3-1.414,1) ;
\draw[thick] (head0) -- (head1) -- (head2) -- (head3) -- (head4) -- (head5) -- (tail0) -- (tail1) -- (tail2) -- (tail3) -- (tail4) -- (tail5) -- (tail6) -- (tail7) -- (tail0) ;
\draw[thin, ->, >= stealth] (3,2) arc (90:-230:1) ;
\draw[thin, >= stealth] (.5,-3) edge[out=135,in=210, ->] (1.2,1.1) ;
\draw (head0) node {$\bullet$};
\draw (head1) node {$\bullet$};
\draw (head2) node {$\bullet$};
\draw (head3) node {$\bullet$};
\draw (head4) node {$\bullet$};
\draw (head5) node {$\bullet$};
\draw (tail0) node {$\bullet$};
\draw (tail1) node {$\bullet$};
\draw (tail3) node {$\bullet$};
\draw (tail4) node {$\bullet$};
\draw (tail5) node {$\bullet$};
\draw (tail6) node {$\bullet$};
\draw (tail7) node {$\bullet$};
\draw[very thin, ->, >= stealth, color=red] (head0) to[bend left=90] (head2);
\draw[very thin, ->, >= stealth, color=red] (head2) to[bend left=90] (head4);
\draw[very thin, ->, >= stealth, color=red] (head4) to[bend left=90] (tail0);
\draw[very thin, ->, >= stealth, color=red] (tail0) to[bend left=90] (tail2);
\draw[very thin, ->, >= stealth, color=red] (tail2) to[bend left=90] (tail4);
\draw[very thin, ->, >= stealth, color=red] (tail4) to[bend left=90] (tail6);
\draw[very thin, ->, >= stealth, color=red] (tail6) to[bend left=90] (tail0);
\draw[very thin, ->, >= stealth, color=black!50!green] (head0) to[bend left=45] (head1);
\draw[very thin, ->, >= stealth, color=black!50!green] (head1) to[bend left=45] (head2);
\draw[very thin, ->, >= stealth, color=black!50!green] (head2) to[bend left=45] (head3);
\draw[very thin, ->, >= stealth, color=black!50!green] (head3) to[bend left=45] (head4);
\draw[very thin, ->, >= stealth, color=black!50!green] (head4) to[bend left=45] (head5);
\draw[very thin, ->, >= stealth, color=black!50!green] (head5) to[bend left=45] (tail0);
\draw[very thin, ->, >= stealth, color=black!50!green] (tail0) to[bend left=45] (tail1);
\draw[very thin, ->, >= stealth, color=black!50!green] (tail1) to[bend left=45] (tail2);
\draw[color=cyan] (tail2) node {$\bullet$} node [above right] {collision au huitième saut};

\end{tikzpicture}

\end{center}
\end{figure}

\subsubsection{Complexité de l'algorithme rho de Pollard}

Sans rentrer dans l'étude de la complexité de l'algorithme, on remarque, grâce à la proposition~\ref{prop:floyd}, que l'épacte est inférieur à $\sqrt{{\pi p}/{2}}$, et donc qu'il y a une collision après avoir calculer $\O(\sqrt p)$ termes de la suite.

\begin{theo}
La complexité de l'algorithme rho de Pollard est de $\O(\sqrt p)$ opérations dans le groupe, et utilise un espace en mémoire constant (par rapport à la taille du groupe).
\end{theo}

\section{Le cryptosystème de Chor-Rivest}\label{sec:cryptosysteme}

Dans leur article~\cite{chorRivest1988} publié en 1988, Benny Chor et Ronald Rivest introduisent un nouveau cryptosystème de chiffrement à clé publique. Ils se sont inspirés du théorème de Bose-Chowla \cite{bose1962} pour créer un cryptosystème reposant sur un problème de sac à dos et résistant à l'attaque de Jeffrey Lagarias et Andrew Odlyzko \cite{lagarias1983} sur les sacs de dos à faible densité.

Avant de donner le théorème de Bose-Chowla, informons qu'ici, le \textit{poids} d'un vecteur d'entiers $(x_0, \dots, x_{p-1})$ est $|x_0| + \dots + |x_{p-1}|$, i.e. sa norme $L^1$.

\begin{theo}[Théorème de Bose-Chowla]
Soient $p$ un nombre premier\footnote{$p$ peut être une puissance de nombre premier, le résultat et sa démonstration restent inchangés.} et $h \geqslant 2$ un entier. Il existe une suite ${(a_i)}_{0\leqslant i \leqslant p-1}$ d'entiers telle que : \begin{enumerate}
\item pour tout $0 \leqslant i \leqslant p-1$, $$1 \leqslant a_i \leqslant p^h-1,$$
\item si $(x_0, \dots, x_{p-1})$ et $(y_0, \dots, y_{p-1})$ sont deux vecteurs distincts d'entiers naturels de poids inférieur à $h$, alors
$$\sum_{i=0}^{p-1} x_ia_i \neq \sum_{i=0}^{p-1} y_ia_i.$$
\end{enumerate}
\end{theo}

\begin{proof}
Dans l'extension de corps finis $\extension{\gf{p^h}}{\gf{p}}$, notons $\gf{p} = \{\alpha_0, \dots, \alpha_{p-1} \}$. Soient $t$ un élément de $\gf{p^h}$ algébrique de degré $h$ sur $\gf{p}$ et $g$ un élément primitif de $\gf{p^h}$. Considérons l'ensemble des translatés de $t$ par un élément de $\gf{p}$, à savoir $\{ t + \alpha_i : \alpha_i \in \gf{p} \}$.

Soit $a_i := \log_g(t + \alpha_i)$, où $\alpha_i \in \gf{p}$, le logarithme de $t+\alpha_i$ en base $g$ dans $\gf{p^h}$. Alors les $a_i$ sont tous des entiers de l'intervalle $\ldbrack1, p^h -1\rdbrack$ et, montrons par l'absurde que, toutes les sommes de $h$ termes de la suite ${(a_i)}_{0\leqslant i \leqslant p-1}$ sont deux à deux distinctes.

Soient deux vecteurs d'entiers naturels $(x_0, \dots, x_{p-1})$ et $(y_0, \dots, y_{p-1})$ distincts et de poids au plus $h$ tels que :
$$\sum_{i=0}^{p-1}x_ia_i = \sum_{i=0}^{p-1}y_ia_i.$$
Il s'en suit l'égalité dans $\gf{p^h}$ : $g^{\sum x_ia_i} = g^{\sum y_ia_i}$, et donc :
$$\prod_{i=0}^{p-1} {\left({g^{a_i}}\right)}^{x_i} = \prod_{i=0}^{p-1} {\left({g^{a_i}}\right)}^{y_i}.$$
En utilisant l'égalité $g^{a_i} = t + \alpha_i$ et en ne considérant que les $x_i$ et $y_i$ non-nuls, nous obtenons :
$$(t+\beta_1)^{x_{i_1}}(t+\beta_2)^{x_{i_2}} \cdots (t+\beta_l)^{x_{i_l}} = (t+\gamma_1)^{y_{j_1}}(t+\gamma_2)^{y_{j_2}} \cdots (t+\gamma_m)^{y_{j_m}},$$
où $\{\beta_1, \dots, \beta_l \}$ et $\{ \gamma_1, \dots, \gamma_m\}$ sont deux sous-ensembles non-vides de $\gf{p}$ de cardinal au plus $h$. Les deux polynômes de part et d'autre de la dernière égalité sont donc distincts, unitaires, de degré au plus $h$ et à coefficients dans $\gf{p}$. Ainsi, en faisant la différence de ces deux polynômes, nous arrivons à la conclusion que $t$ est racine d'un polynôme non-nul de degré au plus $h-1$ et dont les coefficients sont dans $\gf{p}$. Cela contredit le fait que $t$ est algébrique de degré $h$ sur $\gf{p}$.
\end{proof}

\subsection{Description du cryptosystème}

Soient $p$ une puissance non-nulle de nombre premier et $h \geqslant 2$ un entier naturel. Considérons le corps fini à $p^h$ élément, noté $\gf{p^h}$, ainsi qu'une numérotation $\alpha$ du sous-corps de base $\gf{p}$, à savoir $$\{\alpha_0,\dots, \alpha_{p-1}\} = \gf{p} \subset \gf{p^h}.$$

\paragraph{Génération des clés.} Les éléments de la clé privée consistent en :
\begin{enumerate}
\item un générateur $g$ du groupe cyclique $\gf{p^h}^\times$,
\item un élément $t \in \gf{p^h}$ algébrique de degré $h$ sur $\gf{p}$, dont on note $\mu(X) \in \gf{p}[X]$ le polynôme minimal,
\item une permutation $\sigma$ de l'ensemble $\{0, \dots, p-1\}$,
\item un entier $d$ tel que $0 \leqslant d \leqslant p^h-2$.
\end{enumerate}
La clé publique est alors composée des :
$$c_i := d + \log_g\left(t + \alpha_{\sigma(i)}\right) \pmod{p^h-1}, \qquad 0 \leqslant i \leqslant p-1.$$

\'Etant donné qu'il faut calculer des logarithmes discrets pour fabriquer la clé publique, les paramètres choisis doivent faciliter le calcul de ces logarithmes dans $\gf{p^h}$. Ainsi, Chor et Rivest suggèrent de prendre pour $p$ un entier premier petit, ou une puissance de nombre premier petite, et pour $h$ un entier composé, permettant l'utilisation de l'algorithme de Pohlig-Hellman \cite{pohligHellman1978}, exposé en sous-section~\ref{s-sec:pohligHellman}. En l’occurrence, ils ont proposé de se placer dans des corps tels que $\gf{197^{24}}$, $\gf{211^{24}}$, $\gf{243^{24}}$ et $\gf{256^{25}}$.

\paragraph{Espace des messages.}L'espace des messages est l'ensemble des chaînes de $p$ bits et de poids de Hamming égal à $h$. C'est-à-dire que le message à chiffrer doit être une chaîne de bits $m = [m_0\cdots m_{p-1}]$ telle que $m_0+\dots + m_{p-1} = h$. N'importe quel message peut être découpé en plusieurs messages de $p$ bits et de poids $h$ en suivant un algorithme d'encodage donné dans \cite[IV.B.]{chorRivest1988}.

\paragraph{Chiffrement.}L'espace des chiffrés est $\Z/(p^h-1)\Z$ et le chiffré d'un message $m$ est :
$$E(m) := \sum_{i=0}^{p-1} m_ic_i \pmod{p^h-1}.$$
\paragraph{Déchiffrement.}Pour déchiffrer, nous calculons :
$$G(t) := g^{E(m) - hd},$$
vu comme un polynôme en $t$ à coefficients dans $\gf{p}$ et de degré au plus $h-1$. Comme $g$ est primitif dans $\gf{p^h}$, i.e. l'ordre de $g$ est $p^h-1$, l'exposant $E(m) - hd$ est à déterminer modulo $p^h-1$ :

\begin{align*}
E(m) - hd &\equiv \left(\sum_{i=0}^{p-1} m_ic_i\right) - hd \pmod{p^h-1}, \\
&\equiv \left(\sum_{i=0}^{p-1} m_i\left(d + \log_g\left(t + \alpha_{\sigma(i)}\right)\right)\right) - hd \pmod{p^h-1}, \\
&\equiv \left(hd + \sum_{i=0}^{p-1} m_i\log_g\left(t + \alpha_{\sigma(i)}\right)\right) - hd \pmod{p^h-1}, \\
&\equiv  \sum_{i=0}^{p-1} m_i\log_g\left(t + \alpha_{\sigma(i)}\right) \pmod{p^h-1}. \\
\end{align*}
D'où, l'égalité dans $\gf{p^h}$ :
$$G(t) = g^{E(m) - hd} = \prod_{i=0}^{p-1} \left(t+\alpha_{\sigma(i)}\right)^{m_i} = \prod_{m_i = 1} \left(t+\alpha_{\sigma(i)}\right).$$
Cela donne l'expression de l'élément $G(t)$ dans la base $(1,t,t^2, \dots, t^{h-1})$ du $\gf{p}$-espace vectoriel $\gf{p^h}$, où $t = X \pmod{\mu(X)}$. Ainsi :
$$G(X) \equiv \prod_{m_i = 1} \left(X+\alpha_{\sigma(i)}\right) \pmod{\mu(X)}.$$
Il existe donc un polynôme $\lambda(X) \in \gf{p}[X]$ tel que : $$G(X) = \lambda(X) \mu(X) + \prod_{m_i = 1} \left(X+\alpha_{\sigma(i)}\right).$$
En raisonnant sur les degrés, et comme $\mu(X)$ et $\prod \left(X+\alpha_{\sigma(i)}\right)^{m_i}$ sont unitaires, nous déduisons  $\lambda(X) = -1$, dont il découle l'égalité de polynômes :
$$G(X) + \mu(X) = \prod_{m_i = 1} \left(X+\alpha_{\sigma(i)}\right).$$
Ainsi, la factorisation de $G(X)+\mu(X)$ permet de recouvrer le message $m$.

\subsection{Exemple}
Nous nous servons de SageMath pour construire un exemple\footnote{Les lignes de commandes peuvent être copiées telles quelles, elles fonctionnent, mais il est fort probable que les clés ne soient pas les mêmes que dans cet exemple. Les valeurs de $p$ et $h$ peuvent d'ailleurs être changées !

Cet exemple est essentiellement ce qu'il y a dans le fichier \textit{chor-rivest-prime-number.sage}.} d'une instance du cryptosystème de Chor-Rivest. Prenons $p := 17$ et $h := 6$, ainsi $p^h = 24\;137\;569$.
\begin{verbatim}
sage: p = 17
sage: h = 6
sage: q = p ** h
\end{verbatim}
Demandons à SageMath de construire $\gf{17^6}$ :
\begin{verbatim}
sage: K.<a> = FiniteField(q)
sage: P = a.minimal_polynomial()
\end{verbatim}
Le corps fini $\gf{17^6}$ construit est en l’occurrence :
$$\frac{\gf{17}[X]}{(P(X))}, \text{ où } P(X) := X^6 + 2X^4 + 10 X^2 +3X +3\in  \gf{17}[X].$$
Les commandes suivantes permettent d'obtenir une numérotation du sous-corps premier :
\begin{verbatim}
sage: alpha = [K(i) for i in range (p)]
sage: shuffle (alpha)
\end{verbatim}
La numérotation $\alpha$ donnée par SageMath est ici :
$$(\alpha_0, \dots, \alpha_{16}) = (2, 12, 4, 1, 0, 10, 7, 8, 15, 16, 3, 5, 13, 9, 11, 6, 14)$$
\subsubsection{Génération des clés}
Nous souhaitons déterminer un élément primitif $g$ de $\gf{17^6}$ :
\begin{verbatim}
sage: while True :
sage:     g = K.random_element()
sage:     if g.multiplicative_order() == q - 1 :
sage:         break
\end{verbatim}
Notons $a = X \pmod{P(X)}$. L'élément primitif $g$ sélectionné est alors :
$$g := 2a^5 + 5a^4 + 14a^3 + 2a^2 + 10a + 16.$$
Ensuite, pour l'élément algébrique $t$ de degré $6$ sur $\gf{17}$ :
\begin{verbatim}
sage: while True :
sage:     t = K.random_element()
sage:     if t.minimal_polynomial().degree() == h :
sage:         break
sage: mu = t.minimal_polynomial()
\end{verbatim}
Ce code SageMath donne ici :
$$t := 9a^5 + 16a^4 + 10a^3 + 3a^2 + 12a + 12,$$
de polynôme minimal :
$$\mu(X) := X^6 + 9X^5 + 8X^4 + 14X^3 + X^2 + 11X + 6\in\gf{17}[X].$$
La ligne de commande :
\begin{verbatim}
sage: sig = Permutations([i for i in range (p)]).random_element()
\end{verbatim}
sélectionne une permutation $\sigma$ de l'ensemble $\{0, \dots, 16\}$ valant :
$$\sigma := (10, 6, 3, 9, 12, 1, 14, 15, 5, 16, 8, 11, 7, 2, 0, 4, 13).$$
Enfin :
\begin{verbatim}
sage: d = randint (0, q - 2)
\end{verbatim}
assigne la valeur $1\;530\;545$ à l'entier $d$.

Nous avons fini de fabriquer la clé privée ! Reste à construire la clé publique\footnote{À toutes fins utiles, la méthode utilisée par SageMath pour le calcul de logarithme discret est Pohlig-Hellman avec du pas de bébé -- pas de géant.} :
\begin{verbatim}
sage: c = [mod (d + log (t + alpha[sig[i]], g), q - 1) for i in range (p)]
\end{verbatim}
Cela donne :
$$\begin{array}{r c l c r c l c r c l}
c_0 &:=& 21\;667\;185, &&
c_1 &:=& 3\;210\;064, &&
c_2 &:=& 6\;070\;281, \\
c_3 &:=& 3\;093\;929, &&
c_4 &:=& 19\;945\;987, &&
c_5 &:=& 294\;610, \\
c_6 &:=& 4\;230\;580, &&
c_7 &:=& 18\;951\;770, &&
c_8 &:=& 7\;364\;695, \\
c_9 &:=& 23\;348\;812, &&
c_{10} &:=& 7\;918\;908, &&
c_{11} &:=& 3\;562\;855, \\
c_{12} &:=& 6\;735\;636, &&
c_{13} &:=& 13\;077\;876, &&
c_{14} &:=& 11\;303\;489, \\
c_{15} &:=& 22\;106\;426, &&
c_{16} &:=& 18\;193\;975.
\end{array}$$


\subsubsection{Chiffrement d'un message}
Maintenant, donnons nous un message à chiffrer de longueur $17$ et de poids $6$ :
\begin{verbatim}
sage: m = [1 for i in range (h)] + [0 for i in range (p - h)]
sage: shuffle (m)
\end{verbatim}
$$m := [m_0\cdots m_{16}] = [00100101100100100].$$
Chiffrons $m$ :
\begin{verbatim}
sage: e = mod (sum ([m[i]*c[i] for i in range (p)]), q-1)
\end{verbatim}
$$E(m) := 23\;410\;132.$$

\subsubsection{Déchiffrement du message}
Nous souhaitons écrire $g^{E(m) - hd}$ comme un polynôme en $t$. Or SageMath nous donne l'élément $g^{E(m) - hd}$ comme polynôme en $a$ : $$g^{E(m) - hd} = a^5 + 11a^3 + 9a^2 + 15a + 1.$$
Pour parvenir à exprimer $g$ comme nous le souhaitons, il faut effectuer un changement de base du $\gf{17}$-espace vectoriel $\gf{17^6}$ : passer de la base $\mathcal{A} := (1, a, a^2, \dots, a^{h-1})$ à la base $\mathcal{T} := (1, t, t^2, \dots, t^{h-1})$.
La matrice de passage facile à calculer est celle qui passe de la base $\mathcal{T}$ à la base $\mathcal{A}$ : il suffit d'écrire dans SageMath les différentes puissances de $t$, et SageMath les exprime en fonction des puissances de $a$ :
\begin{verbatim}
sage: V = K.vector_space()
sage: M = Matrix (GF(p), [V(t ** i) for i in range (h)]).transpose()
\end{verbatim}
Voici cette matrice :
$$M := \left[\begin{array}{cccccc}
1 & 12 & 7 & 11 & 14 & 0 \\
0 & 12 & 9 & 12 & 6 & 12 \\
0 & 3 & 8 & 3 & 7 & 12 \\
0 & 10 & 0 & 15 & 15 & 14 \\
0 & 16 & 4 & 0 & 13 & 3 \\
0 & 9 & 15 & 10 & 5 & 6 \\
\end{array}\right]$$
Celle qui nous intéresse est son inverse, la matrice de passage de la base $\mathcal{A}$ à la base $\mathcal{T}$ :
\begin{verbatim}
sage: Minv = M.inverse()
\end{verbatim}
$$M^{-1} = \left[\begin{array}{cccccc}
1 & 5 & 10 & 12 & 15 & 11 \\
0 & 8 & 8 & 0 & 11 & 5 \\
0 & 13 & 13 & 9 & 5 & 1 \\
0 & 9 & 10 & 3 & 11 & 9 \\
0 & 12 & 6 & 2 & 16 & 8 \\
0 & 7 & 16 & 2 & 13 & 11 \\
\end{array}\right]$$
Comme $g^{E(m) - hd}$ vaut dans la base $\mathcal{A}$ le vecteur $(1, 15, 9, 11, 0, 1)$, il est facile d'obtenir l'égalité:
$$g^{E(m) - hd} = 10t^5 + 9t^4 + 12t^3 + 4t^2 + 10t + 3.$$
grâce à la commande:
\begin{verbatim}
sage: G = list (Minv * V(g ** (e - h * d)))
\end{verbatim}
Notons $G(X) := 10X^5 + 9X^4 + 12X^3 + 4X^2 + 10X + 3 \in \gf{17}[X]$. Le message est ainsi recouvré en factorisant le polynôme:
$$G(X) + \mu(X) = X^6 + 2X^5 + 9X^3 + 5X^2 + 4X + 9,$$
ce que nous faisons :
\begin{verbatim}
sage: A.<X> = PolynomialRing (GF(p))
sage: S = A(G) + A(mu)
sage: S.factor()
\end{verbatim}
$$G(X) + \mu(X) = (X + 1)(X + 2)(X + 5)(X + 6)(X + 10)(X + 12).$$
Nous pouvons alors déterminer les $\alpha_i$ utilisés et nous savons ainsi que le bit $m_{\sigma^{-1}(i)}$ du message $m$ est à $1$ :
\begin{verbatim}
sage: beta = [p - S.roots()[i][0] for i in range (h)]
sage: sigInv = [sig.index(i) for i in range (p)]
sage: message = [0 for i in range (p)]
sage: for k in beta :
sage:     message[sigInv [alpha.index(k)]] = 1
\end{verbatim}
Par exemple, pour le cas $\alpha_{\sigma(i)} = 1$: nous cherchons d'abord l'indice $j$ tel que $\alpha_j = 1$, à savoir $j = 3$. Puis nous déterminons son antécédent par la permutation : $\sigma^{-1}(3) = 2$. Et on constate en effet $m_2 = 1$.

\section{La cryptanalyse de Serge Vaudenay}\label{sec:cryptanalyse}

Nous présentons ici la cryptanalyse de Serge Vaudenay \cite{vaudenay2000}, publiée en 2000. Elle s'appuie sur la forte friabilité de $h$, i.e. sur l'existence de nombreux sous-corps de $\gf{p^h}$. Cette attaque ne requiert pas d'émission de chiffrés, elle se base seulement sur la connaissance de la clé publique. Elle exploite une caractéristique du cryptosystème, à savoir que par conception, il existe plusieurs clés privées qui produisent la même clé publique.

Ici, nous donnons l'attaque pour $p$ un nombre premier, bien qu'elle soit adaptable pour le cas où $p$ est une puissance d'un nombre premier. En outre, nous exposons l'attaque à rebours, à savoir que nous partons du cas où quelques éléments de la clé privée sont connus et, au fur et à mesure, nous les retirons en regardant comment les retrouver.

\subsection{Notion de clés privées équivalentes}

Dans le cryptosystème de Chor-Rivest, nous choisissons la clé privée de façon aléatoire puis, à partir de celle-ci, nous calculons la clé publique. Cependant, nous remarquons qu'il y a plusieurs clés privées \textit{équivalentes}, à savoir qu'il existe plusieurs jeux de clés privées qui donnent la même clé publique.

Affinons. Nous pouvons remplacer $t$ et $g$ par leur puissance $p$-ième, la clé publique reste inchangée car :
$$\log_{g^p}\left(t^p + \alpha_{\sigma(i)}\right) = \frac{1}{p}\log_{g}\left(\left(t + \alpha_{\sigma(i)}\right)^p\right) = \log_{g}\left(t + \alpha_{\sigma(i)}\right).$$
Nous pouvons aussi remplacer $(t, \alpha_{\sigma})$ par $(t + v, \alpha_{\sigma} - v)$, pour tout $v \in \gf{p}$. Et enfin, nous pouvons remplacer $(t,d,\alpha_\sigma)$ par $(ut, d - \log_g(u), u\alpha_\sigma)$, quel que soit $u \in \gf{p}^\times$.
Cela donne donc, en général, au moins $hp(p-1)$ clés privées équivalentes.

Il s'agit alors de déterminer une de ces clés.

\begin{defi}
Deux clés privées sont dites \textit{équivalentes} si elles produisent la même clé publique. En d'autres termes, deux clés privées $(g,t,\sigma,d)$ et $(g',t',\pi ,d')$ sont équivalentes, si on a l'égalité de suites :
$$\left(d + \log_g(t + \alpha_{\sigma(i)})\right)_{0\leqslant i \leqslant p-1} = \left(d' + \log_{g'}(t' + \alpha_{\pi(i)})\right)_{0\leqslant i \leqslant p-1}.$$
\end{defi}

Pour passer d'une clé privée à une clé privée équivalente, il existe une transformation intéressante sur la permutation $\sigma$ qui permet de choisir arbitrairement deux images pour deux antécédents fixés -- ici, on prend les images de $0$ et $1$ :

\begin{prop}\label{prop:permutation}
Soient $i$ et $j$ deux entiers distincts et $\sigma$ une permutation d'une clé privée, notée $(g,t,\sigma,d)$. Alors, il existe $\pi$ une permutation d'une clé privée équivalente, telle que, $$\pi(0) = i \qquad \text{et}\qquad \pi(1) = j.$$
\end{prop}

\begin{proof}
Posons :
$$\quad u = \frac{\alpha_i - \alpha_j}{\alpha_{\sigma(0)}- \alpha_{\sigma(1)}} \in \gf{p}^\times \quad \text{ et } \quad v =  \frac{\alpha_j\alpha_{\sigma(0)} - \alpha_i\alpha_{\sigma(1)}}{\alpha_{\sigma(0)}- \alpha_{\sigma(1)}} \in \gf{p}.$$
Il faut alors définir la permutation $\pi$ par
$$\alpha_{\pi(i)} = u\alpha_{\sigma(i)} + v,\qquad \forall i : 0\leqslant i \leqslant p-1.$$
La clé privée équivalente est alors $\left(g, ut-v, \pi, d- \log_g(u)\right)$.
\end{proof}

\subsection{Cléf de voûte de l'attaque}\label{s-sec:clefVaudenay}

Serge Vaudenay définit un polynôme bien particulier, qui est la pierre angulaire de son attaque contre le cryptosystème. Le voici:

$$Q(X) = (g_{p^r})^{d} \prod_{i=0}^{h/r-1} \left(X+t^{p^{ri}}\right),
\quad \text{ où } g_{p^r} := \prod_{i=0}^{h/r-1} g^{p^{ri}}.$$

\begin{prop}\label{prop:vaudenay}
Pour tout facteur $r$ de $h$, l'élément $g_{p^r}$ est générateur du groupe multiplicatif du sous-corps $\gf{p^r}$ de $\gf{p^h}$ et $Q(X) \in \gf{p^r}[X]$ est de degré $h/r$, tel que $-t$ en est une racine, et:
$$Q\left(\alpha_{\sigma(i)}\right) = (g_{p^r})^{c_i},\qquad \forall i : 0\leqslant i \leqslant p-1.$$
\end{prop}

\begin{proof}
L'élément $g_{p^r}$ est la norme de $g$ considéré dans l'extension de corps $\extension{\gf{p^h}}{\gf{p^r}}$, ainsi nous avons $( g_{p^r})^{p^r} =  g_{p^r}$ et $ g_{p^r}$ est générateur de $\gf{p^r}^\times$ car $ g$ est primitif dans $\gf{p^h}$. Nous remarquons que $Q\left(X^{p^r}\right) = Q(X)^{p^r}$, ce qui prouve que $Q(X) \in \gf{p^r}[X]$. En effet :
\begin{align*}
Q\left(X\right)^{p^r} &= ( g_{p^r})^{ dp^r} \prod_{i=0}^{h/r-1} \left(X+ t^{p^{ri}}\right)^{p^r}, \\
&= ( g_{p^r})^{ d} \prod_{i=0}^{h/r-1} \left(X^{p^r} +  t^{p^{ri}p^r}\right), \\
&= ( g_{p^r})^{ d} \prod_{i=1}^{h/r} \left(X^{p^r} +  t^{p^{ri}}\right), \\
&= Q\left(X^{p^r}\right), \\
\end{align*}
car $ t^{p^{r(h/r)}} =  t^{p^h} =  t =  t^{p^0}$. Cela montre au passage que $Q(- t) = 0$. Aussi, $Q(X)$ est visiblement un polynôme de degré $h/r$. Et enfin, pour $0\leqslant j \leqslant p-1$, calculons $( g_{p^r})^{c_j}$ :
\begin{align*}
( g_{p^r})^{c_j} &= \left(\prod_{i=0}^{h/r-1}  g^{p^{ri}}\right)^{c_j},\\
&= \prod_{i=0}^{h/r-1} \left( g^{c_j}\right)^{p^{ri}}, \\
&= \prod_{i=0}^{h/r-1}  g^{ dp^{ri}}\left(\alpha_{\sigma(j)} +  t\right)^{p^{ri}},\\
&= ( g_{p^r})^{ d} \prod_{i=0}^{h/r-1} \left(\alpha_{\sigma(j)} +  t^{p^{ri}}\right),\\
&= Q\left(\alpha_{\sigma(j)}\right). \\
\end{align*}
Cela achève la démonstration de la proposition.
\end{proof}

Comme $h/r$ est assez petit et que le polynôme est à coefficients dans le sous-corps $\gf{p^r}$, il est peu probable qu'il existe d'autres éléments $(g_{p^r}, Q(X))$ ayant les mêmes propriétés, et $ g_{p^r}$ est donc essentiellement unique. Soulignons la particularité de ce polynôme $Q(X)$: il est à coefficients dans $\gf{p^r}$, il est de degré $h/r$ et nous connaissons ses images sur tout $\gf{p}$, il peut donc être interpolé sur un petit sous-ensemble de $\gf{p}$.

\paragraph{Notation.} Pour $r$ divisant $h$ et $\omega$ élément de $\gf{p^h}$, notons $$\omega_{p^r} := \omega^{(p^h-1)/(p^r-1)} = \omega^{1+p^r+p^{2r}+p^{3r}+\cdots+p^{h-r}},$$
la norme de $\omega$ considéré dans l'extension de corps $\extension{\gf{p^h}}{\gf{p^r}}$.

\subsection{Comment trouver $t$ sachant $ g_{p^r}$ et $\sigma$}

Supposons connus la norme $g_{p^r}$ de $g$ et la permutation $\sigma$. Nous pouvons alors interpoler le polynôme $Q(X)$ de la sous-section~\ref{s-sec:clefVaudenay}, avec $h/r +1$ paires ${(\alpha_{\sigma(i)}, ( g_{p^r})^{c_i})}$. Cela donne un polynôme de degré $h/r$ dont les racines sont les conjugués de $- t$.  Par équivalence entre clés privées, nous pouvons sélectionner n'importe quelle racine de $Q(X)$. Cet algorithme est l'objet de l'Algorithme~\ref{algo:premiereAttaqueVaudenay}.

Nous finissons l'attaque en calculant ensuite $g$ et $d$ grâce à l'attaque de Oded Goldreich exposée dans \cite[VII.A.3]{chorRivest1988}. Une version simplifiée sera utilisée plus loin, c'est pour cela qu'elle est volontairement omise ici.

\paragraph{Notation.}Étant donné $\sigma$, pour $j$ tel que $0\leqslant j \leqslant h/r$, on note $\mathcal L_j(X)$ le \textit{$j$-ème polynôme interpolateur de Lagrange} :
$$\mathcal L_{j,\sigma}(X) := \prod_{\substack{0\leqslant k\leqslant h/r \\ k \neq j}}\frac{X-\alpha_{\sigma(k)}}{\alpha_{\sigma(j)}-\alpha_{\sigma(k)}}.$$

\begin{algorithm}[h]
\caption{Algorithme pour trouver $t$ sachant $g_{p^r}$ et $\sigma$}
\label{algo:premiereAttaqueVaudenay}
\begin{algorithmic}[1]
\REQUIRE $(c_0,\dots, c_{p-1})$, $\sigma$, $r$ divisant $h$ et $g_{p^r}$
\ENSURE $t, t^{p^r}, t^{p^{2r}}, \dots, t^{p^{h - r}}$
\STATE{$Q(X) \in \gf{p^r}[X]$ : initialiser $Q(X) \gets 0$}
\FOR{$j$ allant de $0$ à $h/r$}
	\STATE{$Q(X) \gets Q(X) + (g_{p^r})^{c_j} \mathcal L_{j,\sigma}(X)$}
\ENDFOR
\RETURN{$[-x \in \gf{p^h}$ pour $x$ racine du polynôme $Q(X) ]$}
\end{algorithmic}
\end{algorithm}

\paragraph{Choix des points d'interpolation.}

Dans son papier, Serge Vaudenay interpole le polynôme $Q(X)$ de la sous-section~\ref{s-sec:clefVaudenay} sur un ensemble quelconque de $h/r+1$ éléments de $\gf{p}$. À savoir, il choisit des indices $i_0, i_1, \dots, i_{h/r}$ pris entre $0$ et $p-1$, deux à deux distincts ; et interpole le polynôme en les éléments $\alpha_{i_j}$ pour $j$ tel que $0 \leqslant j \leqslant h/r$.

Pour simplifier le propos, et surtout pour rendre plus lisible la rédaction, nous faisons le choix ici de prendre $i_j = j$, pour tout $0 \leqslant j \leqslant h/r$. C'est ce qui a été fait dans l'algorithme~\ref{algo:premiereAttaqueVaudenay}.

\subsection{Comment trouver $\sigma$ sachant $g_{p^r}$: l'approche directe}

Supposons connu l'élément $g_{p^r}$. Par la proposition~\ref{prop:vaudenay}, il est possible d'interpoler le polynôme $Q(X)$ en les $\alpha_{\sigma(j)}$, pour $0 \leqslant j \leqslant h/r$:
$$ Q(X) = \sum_{j=0}^{h/r} Q\left(\alpha_{\sigma(j)}\right) \mathcal L_{j,\sigma}(X) = \sum_{j=0}^{h/r} (g_{p^r})^{c_{j}} \mathcal L_{j,\sigma}(X),$$
ce qui donne:
\begin{equation}\label{eqn:interpolation}
(g_{p^r})^{c_i} = \sum_{j=0}^{h/r} (g_{p^r})^{c_{j}} \mathcal L_{j,\sigma}(\alpha_{\sigma(i)}),\qquad \forall i : 0\leqslant i \leqslant p-1.
\end{equation}

Par équivalence entre clés privées et grâce à la proposition~\ref{prop:permutation}, nous pouvons choisir arbitrairement les images $\sigma(0)$ et $\sigma(1)$. L'algorithme naïf \ref{algo:naifgpr} trouve la permutation $\sigma$ en cherchant exhaustivement les valeurs $\sigma(j)$ pour $2\leqslant j \leqslant h/r$, en vérifiant avec l'équation~(\ref{eqn:interpolation}) que la permutation est consistante.

\begin{algorithm}[h]
\caption{Algorithme pour trouver $\sigma$ sachant $g_{p^r}$}
\label{algo:naifgpr}
\begin{algorithmic}[1]
\REQUIRE $(c_0,\dots, c_{p-1})$, $r$ divisant $h$ et $g_{p^r}$
\ENSURE une permutation $\sigma$
\STATE{choisir arbitrairement $\sigma(0)$ et $\sigma(1)$ distincts dans $\{0, \dots, p-1\}$}
\FORALL{$\sigma(2), \sigma(3), \dots, \sigma({h/r})$ distincts deux à deux} \label{boucle:algoNaifgprBoucle}
	\STATE{$S \gets \left\{\sigma(0), \sigma(1), \sigma(2), \dots, \sigma({h/r})\right\}$}
	\FORALL{$\ell \not\in S$} \label{boucle:algoNaifgprBoucle2}
		\STATE{calculer le membre de droite $\mathbf{res}$ de l'équation~(\ref{eqn:interpolation}) avec $\alpha_\ell$ au lieu de $\alpha_{\sigma(i)}$}
		\IF{il existe $i$ tel que $\mathbf{res} = (g_{p^r})^{c_i}$ et $\sigma(i)$ n'est pas définie}
			\STATE{$\sigma(i) \gets \ell$}
			\STATE{$S \gets S \cup \{\sigma(i)\}$}
		\ELSE
			\STATE{continuer la boucle ligne~\ref{boucle:algoNaifgprBoucle}}
		\ENDIF
	\ENDFOR
	\RETURN{$\sigma$}
\ENDFOR
\end{algorithmic}
\end{algorithm}

La complexité de cet algorithme~\ref{algo:naifgpr} est grossièrement $\O((h/r)^2p^{h/r}/(h/r)!)$ opérations dans $\gf{p}$ : la boucle à la ligne~\ref{boucle:algoNaifgprBoucle2} fait $\O(p)$ itérations, chacune avec une complexité $\O((h/r)^2)$, et nous avons besoin\footnote{Si $n\geqslant k \geqslant 1$, alors $\binom{n}{k} \leqslant \frac{n^k}{k!}$.} de $\O(p^{h/r}/(h/r)!)$ itérations de cette boucle.

Maintenant que nous avons obtenu la permutation $\sigma$, nous souhaitons achever l'attaque. C'est ici qu'intervient l'attaque de Goldreich simplifiée susmentionnée. Par équivalence entre clés privées, nous avons calculé les éléments $t$ et $\sigma$ d'une clé privée permettant de produire la clé publique ${(c_i)}_{0 \leqslant i \leqslant p-1}$. Pour compléter cette clé, il nous faut construire $g$ et $d$ satisfaisant à:
$$c_i = d + \log_g(t+\alpha_{\sigma(i)}) \pmod{p^h -1},\qquad \forall i : 0\leqslant i \leqslant p-1.$$
Ainsi, prenons $\gamma$ un élément primitif de $\gf{p^h}$ et posons:
$$b_i := \log_{\gamma}\left(t +\alpha_{\sigma(i)}\right).$$
Notons $L := \log_\gamma(g)$, de sorte que $g = \gamma^L$. Alors, pour tout $i$ tel que $0 \leqslant i \leqslant p-1$:
\begin{align*}
b_i - b_0 &= \log_{\gamma}\left(\frac{t +\alpha_{\sigma(i)}}{t +\alpha_{\sigma(0)}}\right), \\
&= L\log_{g}\left(\frac{t +\alpha_{\sigma(i)}}{t +\alpha_{\sigma(i)}}\right),\\
&= L(c_i - c_0).\\
\end{align*}
Par conséquence, s'il existe un $i$ tel que $(c_i - c_0)$ est inversible modulo $p^h - 1$, nous retrouvons la valeur de $L$ par:
$$L = (b_i - b_0)(c_i - c_0)^{-1} \pmod{p^h-1},$$
ce qui permet de déterminer $g$ et $d$.
L'attaque de Goldreich simplifiée est dépeinte par l'algorithme~\ref{algo:attaqueGoldreichsimplifiee}.

\begin{algorithm}[h]
\caption{Attaque de Goldreich simplifiée}
\label{algo:attaqueGoldreichsimplifiee}
\begin{algorithmic}[1]
\REQUIRE $(c_0,\dots, c_{p-1})$, $t$ et $\sigma$
\ENSURE $g$ et $d$
\STATE{choisir $\gamma$ un élément primitif arbitraire de $\gf{p^h}$}
\STATE{calculer les $b_i := \log_{\gamma}(t+\alpha_{\sigma(i)})$}
\STATE{$B \gets [ b_i - b_0 \pmod{p^h-1}$ pour $i$ allant de $0$ à $p-1 ] $}
\STATE{$C \gets [ c_i - c_0 \pmod{p^h-1}$ pour $i$ allant de $0$ à $p-1 ] $}
\FOR{$i$ allant de $0$ à $p-1$}
	\IF{$\pgcd(C[i], p^h-1) = 1$}
		\STATE{$L \gets C[i]^{-1}B[i] \pmod{p^h-1}$}
		\STATE{$D \gets [L\cdot C[j]$ pour $j$ allant de $0$ à $p-1 ]$}
		\IF[\textit{égalité en tant que suites}]{$D = B$}
			\STATE{$g \gets \gamma^L$}
			\STATE{$d \gets c_0 - \log_g(t+\alpha_{\sigma(0)}) \pmod{p^h -1}$}
			\RETURN{$g, d$}
		\ENDIF
	\ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}

\subsection{Comment trouver $\sigma$ sachant $g_{p^r}$: l'approche avancée}

Quand $r$ est suffisamment grand, il existe un meilleur algorithme pour trouver $\sigma$. Selon Vaudenay~\cite{vaudenay2000}, si $r \geqslant h/r$, alors la famille $\left((g_{p^r})^{c_{j}} - (g_{p^r})^{c_{0}} \right)_{1\leqslant j \leqslant h/r}$ est $\gf{p}$-libre.
Cela signifie que les coefficients dans l'équation (\ref{eqn:interpolation}) sont les seuls coefficients dans $\gf{p}$ de l'écriture du vecteur $(g_{p^r})^{c_{i}} - (g_{p^r})^{c_{0}}$, pour $1\leqslant i \leqslant p-1$, comme combinaison linéaire des vecteurs : $$(g_{p^r})^{c_{1}} - (g_{p^r})^{c_{0}},\quad \dots,\quad (g_{p^r})^{c_{{h/r}}} - (g_{p^r})^{c_{0}}.$$
Cela est résumé dans la proposition suivante :

\begin{prop}Pour tout $i$ tel que $0\leqslant i \leqslant p-1$ :
\begin{equation}\label{eqn:combLineaire}
(g_{p^r})^{c_i} - (g_{p^r})^{c_{0}} = \sum_{j=1}^{h/r} \left((g_{p^r})^{c_{j}} - (g_{p^r})^{c_{0}} \right)\mathcal L_{j,\sigma}(\alpha_{\sigma(i)}).
\end{equation}
\end{prop}

\begin{proof}
Soit $i$ tel que $0 \leqslant i \leqslant {h/r}$ :
$$(g_{p^r})^{c_i} - (g_{p^r})^{c_{0}} = \sum_{j=1}^{h/r} \left((g_{p^r})^{c_{j}} - (g_{p^r})^{c_{0}} \right)\mathcal L_{j,\sigma}(\alpha_{\sigma(i)}).$$
Ainsi, nous avons l'égalité de polynômes :
$$Q(X) - (g_{p^r})^{c_{0}} = \sum_{j=1}^{h/r} \left((g_{p^r})^{c_{j}} - (g_{p^r})^{c_{0}} \right)\mathcal L_{j,\sigma}(X),$$
car les deux polynômes sont de degré $h/r$ et sont égaux sur un ensemble de $h/r + 1$ éléments. D'où l'égalité lorsque les polynômes sont évalués en les $\alpha_{\sigma(i)}$, pour $0\leqslant i \leqslant p-1$.\end{proof}

Notons $a_j^i$ le coefficient de $(g_{p^r})^{c_{{j}}} - (g_{p^r})^{c_{0}}$ pour $(g_{p^r})^{c_{i}} - (g_{p^r})^{c_{0}}$, où $i , j\geqslant 1$. Alors, par l'équation (\ref{eqn:combLineaire}), nous avons, si $a_1^i \neq 0$ :
\begin{align*}
\frac{a_2^i}{a_1^i} &= \left(\prod_{\substack{0\leqslant k\leqslant h/r \\ k \neq 2}} \frac{\alpha_{\sigma(i)}-\alpha_{\sigma(k)}}{\alpha_{\sigma(2)}-\alpha_{\sigma(k)}} \right)\left(\prod_{\substack{0\leqslant k'\leqslant h/r \\ k' \neq 1}} \frac{\alpha_{\sigma(i)}-\alpha_{\sigma({k'})}}{\alpha_{\sigma(1)}-\alpha_{\sigma({k'})}} \right)^{-1}, \\
&= \left(\prod_{\substack{0\leqslant k\leqslant h/r \\ k \neq 2}} \frac{\alpha_{\sigma(i)}-\alpha_{\sigma(k)}}{\alpha_{\sigma(2)}-\alpha_{\sigma(k)}} \right)\left(\prod_{\substack{0\leqslant k' \leqslant h/r \\ k' \neq 1}} \frac{\alpha_{\sigma(1)}-\alpha_{\sigma({k'})}}{\alpha_{\sigma(i)}-\alpha_{\sigma({k'})}} \right), \\
&= \left(\prod_{\substack{0\leqslant k, k'\leqslant h/r \\ k \neq 2, k' \neq 1}} \frac{\alpha_{\sigma(1)}-\alpha_{\sigma({k'})}}{\alpha_{\sigma(2)}-\alpha_{\sigma(k)}} \right) \left(\prod_{\substack{0\leqslant k, k'\leqslant h/r \\ k \neq 2, k' \neq 1}} \frac{\alpha_{\sigma(i)}-\alpha_{\sigma(k)}}{\alpha_{\sigma(i)}-\alpha_{\sigma({k'})}} \right), \\
&= \left(\prod_{\substack{0\leqslant k, k'\leqslant h/r \\ k \neq 2, k' \neq 1}} \frac{\alpha_{\sigma(1)}-\alpha_{\sigma({k'})}}{\alpha_{\sigma(2)}-\alpha_{\sigma(k)}} \right) \left(\frac{\alpha_{\sigma(i)}-\alpha_{\sigma(1)}}{\alpha_{\sigma(i)}-\alpha_{\sigma(2)}} \right). \\
\end{align*}
Ainsi, il existe $\nu$ dans $\gf{p}$, indépendant de $i$, tel que :
\begin{equation}\label{eqn:coeff}
\frac{a_2^i}{a_1^i} = \nu \frac{\alpha_{\sigma(i)}-\alpha_{\sigma(1)}}{\alpha_{\sigma(i)}-\alpha_{\sigma(2)}}\quad\Leftrightarrow\quad
\alpha_{\sigma(i)} = \frac{a_2^i\alpha_{\sigma(2)}-\nu a_1^i\alpha_{\sigma(1)}}{a_2^i-\nu a_1^i}.
\end{equation}
En passant toutes les valeurs de $\nu$ en revue, nous pouvons obtenir $\sigma(i)$ de l'équation (\ref{eqn:coeff}), pour $i$ tel que $0\leqslant i \leqslant p-1$. Cependant, cela ne permet pas de déterminer $\sigma(0)$ et $\sigma(j)$ pour $3 \leqslant j \leqslant h/r$. Il reste alors à les chercher de manière exhaustive. Cette remarque donne naissance à l'algorithme~\ref{algo:gpr}.

\begin{algorithm}[h]
\caption{Algorithme avancé pour trouver $\sigma$ sachant $g_{p^r}$ lorsque $r\geqslant \sqrt h$}
\label{algo:gpr}
\begin{algorithmic}[1]
\REQUIRE $(c_0,\dots, c_{p-1})$, $r$ divisant $h$ tel que $r\geqslant \sqrt h$ et $g_{p^r}$
\ENSURE une permutation $\sigma$
\STATE{choisir arbitrairement $\sigma(1)$ et $\sigma(2)$ distincts dans $\{0, \dots, p-1\}$}
\FORALL{$\nu$ dans $\gf{p}$}\label{boucle:algogpr}
	\FOR{$i$ allant de $h/r+1$ à $p-1$}\label{boucle:algogpr2}
		\STATE{écrire $(g_{p^r})^{c_{i}} - (g_{p^r})^{c_{0}}$ dans la base $\left((g_{p^r})^{c_{j}} - (g_{p^r})^{c_{0}} \right)_{1\leqslant j \leqslant h/r}$}
		\STATE{récupérer les coefficients $a_1^i$ et $a_2^i$}
		\STATE{trouver la valeur de $\sigma(i)$ grâce à l'équation (\ref{eqn:coeff})}
	\ENDFOR
	\STATE{essayer de compléter $\sigma$ en cherchant exhaustivement $\sigma(0)$ et $\sigma(j)$ pour $3 \leqslant j \leqslant h/r$}\label{state:algogpr}
	\IF{$\sigma$ vérifie les équations (\ref{eqn:interpolation})}\label{cond:algogpr}
		\RETURN{$\sigma$}
	\ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}

La complexité de l'algorithme~\ref{algo:gpr} est $\O\left((p+h/r)^3\right)$. Détaillons. On peut calculer la matrice de changement de base en $\O\left((h/r)^3\right)$ opérations. La boucle ligne~\ref{boucle:algogpr2} effectue $\O(p)$ itérations d'une complexité de $\O(h/r)$ chacune, la recherche ligne~\ref{state:algogpr} se fait en $\O(h/r)$ et la condition ligne~\ref{cond:algogpr} se vérifie en $\O\left((h/r)^2\right)$. Tout cela est dans la boucle ligne~\ref{boucle:algogpr} qui se répète $\O(p)$ fois. Ainsi, on atteint la complexité :
$$\O\left(\left(\frac{h}{r}\right)^3 + p\left( p\frac{h}{r} + \frac{h}{r} + \left(\frac{h}{r}\right)^2\right)\right).$$

\subsection{Comment trouver $g_{p^r}$}

Les équations, quel que soit $i$ tel que $0\leqslant i \leqslant p-1$,
$$(g_{p^r})^{c_i} - (g_{p^r})^{c_{0}} = \sum_{j=1}^{h/r} \left((g_{p^r})^{c_{j}} - (g_{p^r})^{c_{0}} \right) \mathcal L_{j,\sigma}(\alpha_{\sigma(i)}),$$
signifient que tous les $(g_{p^r})^{c_i}$ sont en fait dans un même sous-espace affine de dimension $h/r$ du $\gf{p}$-espace vectoriel $\gf{p^r}$. Donc si on suppose que $h/r + 1 \leqslant r$, à savoir $r \geqslant \sqrt{h + 1/4} + 1/2$, on peut donner un test facile pour $g_{p^r}$ :

\begin{prop}
S'il existe un facteur $r$ de $h$ de sorte que $r \geqslant \sqrt{h + 1/4} + 1/2$, alors tous les $(g_{p^r})^{c_i}$ sont sur le même sous-espace affine de dimension $h/r$ de $\gf{p^r}$ lorsque celui-ci est considéré comme un espace affine de dimension $r$ sur $\gf{p}$.
\end{prop}

L'existence d'un tel $r$ peut être considérée comme un mauvais prérequis, cependant vu que les paramètres du cryptosystème de Chor-Rivest ont été choisis de sorte que le problème du logarithme discret soit facile à résoudre, nous savons déjà que $h$ à plusieurs facteurs, et il est donc fort probable que cette hypothèse sur $r$ soit satisfaite. En fait, les seuls $h$ sans de tels facteurs sont les nombres premiers et les carrés de nombres premiers. Le vrai problème est que $r$ ne doit pas être trop grand pour la cryptanalyse, sinon la recherche d'un $g_{p^r}$ devient fastidieuse.

Nous pouvons écrire l'algorithme \ref{algo:testgpr} qui vérifie si un candidat pour $g_{p^r}$ est bon : l'algorithme vérifie simplement si les $(g_{p^r})^{c_i}$ sont sur un même espace affine de dimension $h/r$. La condition ligne~\ref{cond:algoTestgpr} se vérifie en $\O(h^3/r)$ opérations dans $\gf{p}$. Comme il y a $\phi(p^r-1)/r$ candidats, nous pouvons chercher exhaustivement un $g_{p^r}$ avec une complexité de $\O(h^3p^r/r^2)$.

\begin{algorithm}[h]
\caption{Algorithme pour trouver $g_{p^r}$ lorsque $r\geqslant \sqrt{h + 1/4} + 1/2$}
\label{algo:testgpr}
\begin{algorithmic}[1]
\REQUIRE $(c_0,\dots, c_{p-1})$ et $r$ divisant $h$ tel que $r\geqslant \sqrt{h + 1/4} + 1/2$
\ENSURE un élément $g_{p^r}$
\FORALL{$\zeta \in \gf{p^h}$ générateur de $\gf{p^r}^\times$} \label{boucle:algoTestgpr}
	\FORALL{$i$ allant de $h/r + 1$ à $p-1$}
		\IF{$\zeta^{c_{i}}$ n'appartient pas au sous-espace affine engendré par $(\zeta^{c_{0}}, \dots, \zeta^{c_{{h/r}}})$}\label{cond:algoTestgpr}
			\STATE{continuer la boucle ligne~\ref{boucle:algoTestgpr}}
		\ENDIF
	\ENDFOR
	\RETURN{$\zeta$}
\ENDFOR
\end{algorithmic}
\end{algorithm}

\subsection{Comment trouver $g_{p^r}$ en s'aidant des $c_i$}

En 1991, Hendrik Lenstra \cite{lenstra1991} soupçonnait qu'inclure tous les $c_i$ dans la clé publique compromettrait la sécurité du système. Et en effet, Serge Vaudenay a amélioré la recherche précédente en utilisant la connaissance de tous les $c_i$.

Avant de voir comment il a procédé, voici un fait dont nous allons nous servir :

\begin{prop}\label{prop:faitCool}
Soit $Q(X)$ un polynôme de $\gf{p^r}[X]$ de degré $d$ et soit $e$ un entier tel que $1 \leqslant e < (p-1)/d$. Alors : $$\sum_{a \in \gf{p}} Q(a)^e = 0.$$
\end{prop}
Le lemme qui suit permet de démontrer cette proposition.

\begin{lemm}
Soit $k$ un entier tel que $1 \leqslant k < p-1$. Alors
$$\sum_{a\in\gf{p}} a^k = 0.$$
Ainsi, si $P(X) \in \gf{p^r}[X]$ est de degré inférieur à $p-1$, alors : $$\sum_{a\in\gf{p}} P(a) = 0.$$
\end{lemm}

\begin{proof}[Démonstration de la proposition]
Comme $Q(X) \in \gf{p^r}[X]$ est de degré $d$ et que $e$ est tel que $1\leqslant e < (p-1)/d$, le polynôme $Q(X)^e$ est de degré inférieur à $p-1$. Le lemme précédent conclut :
$$\sum_{a\in\gf{p}} Q(a)^e = 0.$$
\end{proof}

Cela nous donne un critère particulièrement intéressant pour $g_{p^r}$ :
\begin{prop}
Pour tout $1 \leqslant e < (p-1)r/h$ :
$$\sum_{i=0}^{p-1} (g_{p^r})^{ec_i} = 0.$$
\end{prop}
\begin{proof}
Considérons le polynôme $Q(X)\in\gf{p^r}[X]$ de la sous-section~\ref{s-sec:clefVaudenay}: le polynôme $Q(X)$ est de degré $h/r$, à coefficients dans $\gf{p^r}$ et tel que, pour tout $0 \leqslant i \leqslant p-1$:
$$Q\left(\alpha_{\sigma(i)}\right) = (g_{p^r})^{c_i}.$$
Ainsi par la proposition~\ref{prop:faitCool}, pour tout $1 \leqslant e < (p-1)r/h$:
$$\sum_{a\in\gf{p}} Q(a)^e = \sum_{i=0}^{p-1} Q\left(\alpha_{\sigma(i)}\right)^e = 0,$$
d'où l'égalité souhaitée:
$$\sum_{i=0}^{p-1} (g_{p^r})^{ec_i} = 0.$$
\end{proof}
\noindent Cela donne une façon plus simple, par rapport à la recherche exhaustive, de sélectionner tous les candidats pour $g_{p^r}$. Son principal avantage est qu'elle fonctionne dans n'importe quel sous-corps. Par exemple, on peut considérer $r=1$ et trouver les seuls $g_p$ tels que pour tout $1 \leqslant e < (p-1)/h$ :
$$\sum_{i=0}^{p-1} (g_p)^{ec_i} = 0.$$
La complexité moyenne pour vérifier un candidat est $\O(p)$ $\gf{p}$-opérations, et il est peu probable qu'un mauvais candidat ne soit pas détecté par le cas $e = 1$. Ainsi, nous pouvons recouvrer $g_p$ en $\O(p^2)$ opérations élémentaires.

Malheureusement, le $g_{p^r}$ ne peut pas être utilisé efficacement quand $r$ est trop petit. Toutefois, si on a calculé des $g_{p^{r_i}}$ dans des petits sous-corps $\gf{p^{r_i}}$, on peut s'aider de ceux-ci pour calculer un $g_{p^r}$ dans un plus grand sous-corps. En fait, notre objectif est de calculer $g_{p^r}$ avec $r$ tel que $r \geqslant h/r + 1$.

Considérons le problème du calcul de $g_{p^r}$ lorsque les facteurs $r_1,\dots,r_k$  de $r$ sont connus, et les $g_{p^{r_i}}$ pour $1 \leqslant i \leqslant k$, sont connus. Comme $g_{p^{r_i}} = (g_{p^r})^{1+p^{r_i}+p^{2r_i}+\cdots+p^{r-r_i}}$, nous avons
\begin{equation}\label{eqn:loggpr}
\log(g_{p^r}) = \frac{\log(g_{p^{r_i}})}{1+p^{r_i}+p^{2r_i}+p^{3r_i}+\cdots+p^{r-r_i}} \pmod{p^{r_i}-1},
\end{equation}
où la base des logarithmes est n'importe quel élément primitif $\gamma$ fixé dans le corps $\gf{p^r}$. La connaissance de tous les $\log(g_{p^{r_i}})$ donne donc la connaissance de $\log(g_{p^r})$ modulo
$$\ell := \ppcm \left\{p^{r_1} - 1, p^{r_2}-1, \dots, p^{r_k} -1\right\}.$$
Nous avons donc besoin seulement de $(p^r-1)/\ell$ essais pour recouvrer $g_{p^r}$.
Cela permet d'écrire l'algorithme~\ref{algo:gprFromgpri}, recouvrant $g_{p^r}$ à partir des $g_{p^{r_i}}$.

\begin{algorithm}[h]
\caption{Algorithme pour récupérer $g_{p^r}$ à partir des $g_{p^{r_i}}$}
\label{algo:gprFromgpri}
\begin{algorithmic}[1]
\REQUIRE $(c_0,\dots, c_{p-1})$, $r$ divisant $h$, ${\{r_i\}}_{1\leqslant i\leqslant k}$ diviseurs de $r$ et $g_{p^{r_i}}$
\ENSURE l'ensemble des $g_{p^r}$ possibles
\STATE{choisir $\gamma$ un élément primitif de $\gf{p^r}$}
\FORALL{$i$ allant de $1$ à $k$}
	\STATE{résoudre l'équation (\ref{eqn:loggpr}) : $$x_i = \frac{\log(g_{p^{r_i}})}{1+p^{r_i}+p^{2r_i}+p^{3r_i}+\cdots+p^{r-r_i}} \pmod{p^{r_i}-1}$$}
\ENDFOR
\STATE{$\ell \gets \ppcm \left\{p^{r_1} - 1, p^{r_2}-1, \dots, p^{r_k} -1\right\}$}
\STATE{résoudre $x \equiv x_i \pmod{p^{r_i}-1}$, pour $1 \leqslant i \leqslant k$ et où $x$ est unique modulo $\ell$ (CRT)}
\FOR{$y$ allant de $0$ à $(p^r-1)/\ell - 1$}\label{boucle:algogprFromgpri}
	\FOR{$e$ allant de $1$ à $(p-1)r/h - 1$}
		\IF{$\sum_{i=0}^{p-1} \gamma^{ec_i(x+\ell y)} \neq 0$}
			\STATE{continuer la boucle ligne~\ref{boucle:algogprFromgpri}}
		\ENDIF
	\ENDFOR
	\STATE{ajouter $\gamma^{x+\ell y}$ à la liste des $ g_{p^r}$ possibles}
\ENDFOR
\end{algorithmic}
\end{algorithm}

Chaque boucle de la ligne~\ref{boucle:algogprFromgpri} de l'algorithme~\ref{algo:gprFromgpri} demande en moyenne $\O(p^2r)$ opérations dans $\gf{p}$.

\subsection{Attaque globale}

Pour l'attaque, on s'intéresse aux sous-corps de $\gf{p^r}$.

\begin{defi}
Soit $G$ un graphe orienté acyclique (DAG pour \textit{directed acyclic graph}) étiqueté enraciné satisfaisant aux conditions: \begin{enumerate}
\item la racine est étiquetée par un sous-corps de $\gf{p^r}$,
\item le sommet sans arc sortant est étiqueté par $\gf{p^r}$,
\item pour chaque arête $u \rightarrow v$ de $G$, l'étiquette $L(u)$ de $u$ est un sous-corps strict maximal (au sens de l'inclusion) de l'étiquette $L(v)$ de $v$.
\end{enumerate}
On dit que $G$ est un \textit{DAG $p$-factorisant} de $\gf{p^r}$.
\end{defi}

\begin{rema}
Tous les sous-corps de $\gf{p^r}$ n'apparaissent pas forcement comme sommet dans un DAG $p$-factorisant de $\gf{p^r}$.
\end{rema}

\begin{exem}
Soit $p$ un nombre premier. Plaçons nous dans le corps $\gf{p^{24}}$, i.e. $h := 24$. L'attaque que nous échafaudons préconise de prendre $r = 6$ comme diviseur de $24$. Soit $G$ le DAG $p$-factorisant de $\gf{p^6}$, en figure~\ref{fig:dag}.
\begin{figure}[h]\caption{DAG $p$-factorisant de $\gf{p^{6}}$}
\begin{center}
\begin{tikzpicture}
\coordinate (F) at (0,0) ;
\coordinate (F2) at (-1.5,1.5) ;
\coordinate (F6) at (0,3) ;
\coordinate (F3) at (1.5,1.5) ;
\draw (F) node[below]{$\gf{p}$} node{$\bullet$} ;
\draw (F2) node[left]{$\gf{p^2}$} node{$\bullet$} ;
\draw (F6) node[above]{$\gf{p^6}$} node{$\bullet$} ;
\draw (F3) node[right]{$\gf{p^3}$} node{$\bullet$} ;
\draw[thick, ->, >= latex] (F) -- (F2) ;
\draw[thick, ->, >= latex] (F) -- (F3) ;
\draw[thick, ->, >= latex] (F2) -- (F6) ;
\draw[thick, ->, >= latex] (F3) -- (F6) ;
\end{tikzpicture}
\label{fig:dag}
\end{center}
\end{figure}
\end{exem}

\begin{defi}
\`A une extension $\gf{p^r}$ et $G$ son DAG $p$-factorisant, on associe :
$$C(G) := \sum_{v} \frac{\#L(v) -1}{\ppcm\{\#L(w)-1 \mid v \leftarrow w\}},$$
où on prend pour convention : $\ppcm(\emptyset) = 1$.
\end{defi}

\begin{exem}
Reprenons l'exemple précédent :
$$C(G) = \frac{p^6 - 1}{\ppcm(p^2-1, p^3-1)} + \frac{p^3-1}{p-1} + \frac{p^2}{p-1} + p-1.$$
Pour $p = 197$, cela donne $C(G) = 78\;014$.
\end{exem}

Nous pouvons définir un algorithme pour calculer $g_{p^r}$ avec pour complexité $\O(pr^2C(G))$, où $G$ est un DAG $p$-factorisant de $\gf{p^r}$. Donc, nous pouvons casser le cryptosystème de Chor-Rivest où le paramètre $h$ n'est ni un nombre premier, ni un carré de nombre premier, avec une complexité de:
$$\O\left(\min_{\substack{r \text{ divisant } h \\ r^2 \geqslant h}} \; \min_{\substack{G \text{ est un DAG}\\p\text{-factorisant} \\ \text{ de } \gf{p^r}}} \;
p^2rC(G)\right).$$
L'algorithme~\ref{algo:attaqueGenerale} illustre l'attaque complète de Serge Vaudenay.

\begin{algorithm}[h]
\caption{Attaque globale}
\label{algo:attaqueGenerale}
\begin{algorithmic}[1]
\REQUIRE $(c_0,\dots, c_{p-1})$
\ENSURE une clé secrète
\STATE{pour le plus petit facteur $r$ de $h$ tel que $r \geqslant \sqrt{h + 1/4} + 1/2$, trouver $G$ un DAG $p$-factorisant minimisant $C(G)$}
\FORALL{$s$ sommet de $G$, tel que pour tout $s \leftarrow s_i$, $s_i$ a été visité,}
	\STATE{l'algorithme~\ref{algo:gprFromgpri} avec $\gf{p^r}=L(s)$ et $\gf{p^{r_i}} = L(s_i)$}
\ENDFOR
\STATE{$\sigma \gets$ appliquer l'algorithme~\ref{algo:gpr} à $g_{p^r}$}
\STATE{$t \gets$ appliquer l'algorithme~\ref{algo:premiereAttaqueVaudenay} à $g_{p^r}$ et $\sigma$}
\STATE{$g, d \gets$ appliquer l'algorithme~\ref{algo:attaqueGoldreichsimplifiee} à $t$ et $\sigma$}
\RETURN{$(g,t,\sigma,d)$}
\end{algorithmic}
\end{algorithm}

\subsection{Conclusion}

Serge Vaudenay a décrit une attaque du cryptosystème, lorsque $h$ admet un facteur $r$ tel que $r \geqslant \sqrt{h + 1/4} + 1/2$, ayant pour complexité $\O(h^3p^r/r^2)$.
La figure~\ref{fig:tabVaudenay} rassemble dans un tableau les diverses attaques exposées dans cette section.

Nous avons implémenté\footnote{Consulter le fichier \textit{vaudenay-attack.sage}} l'attaque en SageMath, bien que les résultats ne soient pas aussi bons que ceux de Serge Vaudenay : 1 heure et demie en moyenne contre 15 minutes, pour les corps $\gf{197^{24}}$ et $\gf{211^{24}}$.

Les préconisations de Serge Vaudenay pour réparer le cryptosystème de Chor-Rivest sont les suivantes : \begin{itemize}
\item choisir un corps fini $\gf{p^h}$ avec $p$ et $h$ tous les deux premiers,
\item ne pas divulguer tous les $c_i$ dans la clé publique.
\end{itemize}


\begin{figure}[h]
\caption{Tableau récapitulant les différentes attaques}
\begin{center}\label{fig:tabVaudenay}
\begin{tabular}{ccccc}
  \toprule
  Algorithme & Paramètre $r$ divisant $h$ & Entrée & Sortie & Complexité dans $\gf{p}$\\
  \midrule
  \midrule
  \ref{algo:premiereAttaqueVaudenay} (p.\pageref{algo:premiereAttaqueVaudenay}) &  & $g_{p^r}$, $\sigma$ & $t$ & \\
  \midrule
  \ref{algo:naifgpr} (p.\pageref{algo:naifgpr})& & $g_{p^r}$ & $\sigma$ & $\O\left(\left(\frac{h}{r}\right)^2\frac{p^{h/r}}{(h/r)!}\right)$ \\
  \midrule
  \ref{algo:attaqueGoldreichsimplifiee} (p.\pageref{algo:attaqueGoldreichsimplifiee})& & $t, \sigma$ & $g, d$ & \\
  \midrule
  \ref{algo:gpr} (p.\pageref{algo:gpr})& $r \geqslant \sqrt{h}$ & $g_{p^r}$ & $\sigma$ & $\O\left(\left(p+\frac{h}{r}\right)^3\right)$\\
  \midrule
  \ref{algo:testgpr} (p.\pageref{algo:testgpr})& $r \geqslant \sqrt{h+1/4}+1/2$ &  & $g_{p^r}$ & $\O\left({h^3p^r}/{r^2}\right)$ \\
  \midrule
  \ref{algo:gprFromgpri} (p.\pageref{algo:gprFromgpri})& ${\{r_i\}}_{1\leqslant i \leqslant k}$ diviseurs de $r$& ${\left\{g_{p^{r_i}}\right\}}_{1\leqslant i \leqslant k}$ & $g_{p^r}$ & $\O(p^2r)$ \\
  \midrule
  \ref{algo:attaqueGenerale} (p.\pageref{algo:attaqueGenerale})& $r \geqslant \sqrt{h+1/4}+1/2$ & & $g, t, \sigma, d$ & $\O\left({h^3p^r}/{r^2}\right)$\\
  \bottomrule
\end{tabular}
\end{center}
\end{figure}

\section{Le calcul de logarithme discret selon Antoine Joux}\label{sec:DLPJoux}

%(Luca) Explique pourquoi tu t'intéresses à ça, quel est le rapport avec la section précédente.

Dans son article \cite{joux2013} de 2013, Antoine Joux conçoit un algorithme permettant un calcul rapide de logarithme discret dans un corps fini de petite caractéristique. Dans la section suivante (\ref{sec:consequences}), nous discuterons de son utilisation dans notre cas, à savoir calculer les logarithmes discrets parmettant de fabriquer la clé publique du cryptosystème de Chor-Rivest \cite{chorRivest1988}.

En imitant la thèse \cite{pierrot2016} de Cécile Pierrot, soutenue en 2016, nous faisons un historique des différents algorithmes dont s'est inspiré Antoine Joux, et nous donnons un algorithme aidant à comprendre ce qu'est la \textit{méthode du calcul d'indice}.

Nous allons donc passer en revue les algorithmes de Hellman-Reyneri et de Coppersmith, ainsi que le crible de corps de fonctions et la descente special-$\mathfrak{q}$, avant de décortiquer l'article \cite{joux2013} d'Antoine Joux. Mais d’abord, donnons quelques notions liminaires et le squelette de la méthode de calcul d’indice.

\subsection{Préliminaires}

Soient $p$ un nombre premier, $q$ une puissance non-nulle de $p$ et $k$ un entier naturel non-nul. On souhaite dans la suite résoudre le problème du logarithme discret dans $\gf{q^k}$, un corps fini à $q^k$ éléments.

On adopte la notation suivante pour donner la \textit{complexité d'un algorithme} :
$$L_{Q}(\alpha, c) := \exp\left({(c+\o(1))(\log Q)^\alpha(\log\log Q)^{1 - \alpha}}\right),$$
où $Q$ est le cardinal du corps considéré, $0 \leqslant \alpha\leqslant 1$ et $c > 0$. Lorsque $\alpha = 0$, l'algorithme est dit \textit{polynomial}, si $0 < \alpha < 1$ alors l'algorithme est dit \textit{sous-exponentiel}, et enfin quand $\alpha = 1$, l'algorithme est dit \textit{exponentiel}. Notons aussi que la constante $c$ est souvent omise, la notation devenant simplement $L_{Q}(\alpha)$.

La notion de \textit{petite, moyenne et grande caractéristique} est définie grâce à la notation précédente. À savoir, on commence par écrire $p = L_{p^n}(\ell,c)$ avec $0\leqslant\ell\leqslant 1$ et $c$ une constante proche de $1$. Si $\ell < 1/3$, on parle de petite caractéristique, si $1/3 < \ell < 2/3$, de moyenne caractéristique, et de grande caractéristique si $\ell > 2/3$.

\begin{defi}
Un polynôme $P(X) \in \gf{q}[X]$ est dit \textit{$d$-friable} s'il se factorise en produit de polynômes de $\gf{q}[X]$ de degré au plus $d$.
\end{defi}

Selon un résultat de Daniel Panario, Xavier Gourdon et Philippe Flajolet \cite{PGF98}, une estimation de la probabilité qu'un polynôme aléatoire de degré inférieur à $n$ soit $d$-friable est :
$${(n/d)}^{-n/d + \o(1)},$$
pour certaines valeurs de $n$ grand et $d$ petit non détaillées ici.

Dans un corps fini, le logarithme discret de $h \in \gf{q^k}$ en base $g \in \gf{q^k}$, où $g$ est primitif, est l'entier $a$, déterminé modulo l'ordre de $g$, tel que $h = g^a$. Concrètement, on s'est donné une représentation du corps fini $\gf{q^k}$, à savoir un polynôme irréductible de degré $k$, noté $J_k(X) \in \gf{q}[X]$. Et les éléments de $\gf{q^k}$ sont alors vus comme des polynômes modulo $J_k(X)$ :
$$\gf{q^k} \cong \frac{\gf{q}[X]}{(J_k(X))}.$$

\subsubsection{Description de la méthode du calcul d'indice}
La plupart des algorithmes de calcul de logarithme discret commencent par la recherche d'une \textit{autre représentation du corps $\gf{q^k}$}. Pour cela, ils sélectionnent un polynôme irréductible de degré $k$, notons-le $I_k(X) \in \gf{q}[X]$. Le changement de représentation se fait de la façon suivante : soit $\alpha$ une racine du polynôme $I_k(X)$ et considérons $J_k(X)$ comme un polynôme à coefficients dans $\gf{q^k} \cong \gf{q}[\alpha]$. Ainsi $J_k(X) \in \gf{q}[\alpha][X]$ est scindé, et on peut exprimer toutes ses racines comme des polynômes en $\alpha$. Choisissons l'une d'entre elles au hasard et notons-la $\beta$. Il est possible d'écrire $\beta = f(\alpha)$, où $f(X) \in \gf{q}[X]$. Dans le problème initial, $g$ et $h$ sont donnés comme des polynômes en $\beta$, disons $G(\beta)$ et $H(\beta)$, où $G(X)$ et $H(X)$ sont à coefficients dans $\gf{q}$. Dans la nouvelle représentation, il suffit de trouver le logarithme discret de $H(f(\alpha))$ en base $G(f(\alpha))$.

Ensuite, il faut déterminer un ensemble de $\gf{q^k}^\times$, que l'on nomme \textit{base de friabilité}, dont les éléments sont considérés comme \og{}petits \fg{}. La plus part du temps, on fixe $d$ un entier assez petit, et les éléments de la base de friabilité sont ceux de la forme $F(\alpha)$, où $F(X)\in\gf{q}[X]$ est un polynôme de degré au plus $d$.

\begin{rema}
On se permet de faire l'amalgame entre deux objets : à savoir entre un \textit{élément du corps} appartenant à la base de friabilité et le \textit{polynôme} ayant servi à le représenter. Par exemple, si $h = H(\alpha)\in\gf{q^k}$ appartient à la base de friabilité, on dira indistinctement que $h$  appartient à la base de friabilité ou bien que $H(X)$ appartient à la base de friabilité.
\end{rema}

Vient après la \textit{phase de collecte de relations} ou \textit{phase de crible}, à savoir, si la base de friabilité utilisée est $\{g_i : i \in I\}$, nous nous intéressons à des relations de la forme :
$$\prod_{i\in I} {g_i}^{u_i} = \prod_{i\in I} {g_i}^{v_i},$$
les $u_i$ et les $v_i$ étant définis modulo $q^k-1$. En termes de logarithmes discrets, cela donne :
$$\sum_{i\in I} u_i \log_gg_i = \sum_{i\in I} v_i \log_gg_i \pmod{q^k-1}.$$
La collecte s’arrête lorsque nous avons suffisamment d'équations pour résoudre le système linéaire associé, sachant que les inconnues sont les $\log_gg_i$ pour  $i\in I$.

Il s'ensuit la résolution dudit système linéaire donné par les équations précédentes, appelée \textit{phase d'algèbre linéaire}. Nous ne nous épanchons pas ici sur les méthodes de résolutions, il faut juste savoir que le système produit est creux et que donc la complexité de cette phase peut être estimée quadratique. Le lecteur intéressé pourra lire entre autres les papiers de Don Coppersmith, Andrew Odlyzko, et Richard Schroeppel \cite{coppersmith1986} et de Douglas Wiedemann \cite{wiedemann1986}.

Enfin, comme nous cherchons à déterminer le logarithme d'un élément arbitraire du corps, on passe à la \textit{phase de logarithme individuel}. L'essence de l'idée est ici d'exprimer l'élément arbitraire en fonction des éléments de la base de friabilité, pour en déduire son logarithme.

En résumé, un algorithme implémentant la méthode du calcul d'indice peut se diviser en quatre étapes: \begin{enumerate}
\item le changement de représentation du corps et le choix de la base de friabilité,
\item la phase de collecte de relations entre les éléments de la base de friabilité,
\item la phase d'algèbre linéaire pour déterminer le logarithme de chaque élément de la base de friabilité,
\item la phase de logarithme individuel qui permet de d'obtenir le logarithme de n’importe quel élément du corps.
\end{enumerate}

\subsubsection{Heuristique de la méthode du calcul d'indice}

Les algorithmes par calcul d'indice reposent sur l'idée de décomposer des éléments comme produits d'éléments considérés comme \og{}petits\fg{}. Les éléments qui peuvent se factoriser de cette manière sont dits friables. Un problème essentiel pour l'analyse de ces algorithmes consiste à estimer la probabilité d'obtenir de tels éléments friables. Dans de nombreux cas, nous procédons heuristiquement en supposant que les éléments créés se comportent comme des éléments aléatoires de même taille. Bien qu'inélégante, car non prouvée, cette heuristique a permis d'obtenir de nombreux progrès algorithmiques.

Autant que faire se peut, nous mettrons en exergue le(s) heuristique(s) employé(s) par chaque méthode ou algorithme.

\subsection{Algorithme de Hellman-Reyneri en $L_{Q}(1/2)$}

Choisissons $g$ un générateur du groupe multiplicatif $\gf{q^k}^\times$ et un entier $d$ tel que $1 < d < k$. L'algorithme de Martin Hellman et Justin Reyneri \cite{hellman1982} commence par sélectionner arbitrairement un polynôme $I_k(X) \in \gf{q}[X]$ unitaire irréductible de degré $k$, afin de représenter $\gf{q^k}$ comme $\gf{q}[\alpha]$, où $\alpha$ est une racine fixée de $I_k(X)$.

Remarquons ensuite que pour $r \in \ldbrack 0, q^k - 2 \rdbrack$ choisi aléatoirement de façon uniforme, $g^r$ est aussi un élément de $\gf{q^k}^\times$ choisi aléatoirement de façon uniforme. Cet élément peut être représenté comme un polynôme $G_r(X) \in \gf{q}[X]$ de degré au plus $k-1$. Si $G_r(X)$ est $d$-friable, nous écrivons :
$$g^r = \beta \prod_{i=1}^{t} F_i(\alpha)^{e_i},$$
où les $F_i(X)\in \gf{q}[X]$ sont les polynômes irréductibles unitaires de degré au plus $d$ apparaissant dans la factorisation de $G_r(X)$ et $\beta$ est le coefficient dominant de $G_r(X)$. En prenant les logarithmes discrets, nous obtenons :
\begin{equation}\label{eqn:hellman-reyneri}
r = \log_g(\beta) + \sum_{i=1}^t e_i\log_g\big(F_i(\alpha)\big) \pmod{q^k - 1}.
\end{equation}

En faisant varier $r$, on obtient d'autres équations ($\beta$, $t$, $e_i$ et $F_i(X)$ dépendent de $r$), les inconnues étant les logarithmes des éléments de l'ensemble :
$$\mathcal{F} =  \gf{q} \cup \{F(\alpha) : F(X) \in \gf{q}[X] \text{ irréductible unitaire de degré au plus } d \}.$$
$\mathcal{F}$ est notre base de friabilité et son cardinal est plus petit que $q^{d+1}$. Nous nous servons de l'heuristique suivante pour borner le nombre de tirages nécessaires :
\begin{heur}
La création de $q^{d+1}$ équations de la forme (\ref{eqn:hellman-reyneri}) permet d'écrire un système admettant une unique solution, formée des logarithmes en base $g$ des éléments de $\mathcal{F}$.
\end{heur}

Une fois que les logarithmes de la base $\mathcal{F}$ sont connus, nous cherchons le logarithme d'un élément arbitraire $h \in \gf{q^k}$ : il suffit d'avoir une relation de la même forme que (\ref{eqn:hellman-reyneri}) faisant intervenir $h$. On peut, par exemple, chercher le logarithme d'un élément $hg^r$ qui se factorise en éléments de la base $\mathcal{F}$ et déduire le logarithme de $h$.

\begin{rema}
Normalement, les éléments de $\gf{q^k}$ dont l'ordre est un petit diviseur de $q^k-1$, comme les éléments de $\gf{q}$, sont écartés lors du crible : ils augmentent la possibilité d'apparition d'éléments non inversibles pour déterminer le logarithme des éléments de la base de friabilité, et des algorithmes tels que Pohlig-Hellman \cite{pohligHellman1978} et rho de Pollard \cite{pollard1978}, sous-sections~\ref{s-sec:pohligHellman} et~\ref{s-sec:rho} respectivement, permettent déjà de les calculer facilement.
\end{rema}

Puisque ici la phase de calcul de logarithme discret individuel est négligeable comparée aux pré-calculs, il suffit, pour analyser la complexité asymptotique d'un tel algorithme, d'exprimer le coût de la collecte des relations et de l'algèbre linéaire en fonction du paramètre $d$. En majorant par $q^{d+1}$ le cardinal de $\mathcal{F}$ et en désignant par $\mathbb{P}$ la probabilité qu'un polynôme aléatoire $G_r(X)$ soit $d$-friable, le coût de l'exécution de la phase de collecte des relations est alors majoré par $q^{d+1}/\mathbb{P}$, en négligeant le coût de la factorisation des polynômes.
En ce qui concerne l'algèbre linéaire, on remarque que le nombre d'éléments de la base de friabilité apparaissant dans n'importe laquelle des relations formées est majorée par $k$. Ceci provient du fait que le nombre de polynômes irréductibles qui apparaissent lorsque l'on factorise un polynôme est toujours inférieur à son degré. Aussi, l’algèbre linéaire que l'on exécute s'attache toujours à une matrice très creuse qui contient au plus $k$ termes non nuls par ligne. Le coût d'une telle méthode est alors quadratique en la taille de $\mathcal{F}$, si on utilise des techniques de calculs sur matrices creuses, comme par exemple la méthode du gradient conjugué. Plus précisément, le temps de calcul est majoré par $kq^{2d+2}$.
De l'estimation de Panario-Gourdon-Flajolet \cite{PGF98}, on écrit :
$$-\log_q(\mathbb{P}) \leqslant\frac{k}{d}\log_q(k/d).$$
Par conséquent, si on choisit le paramètre :
$$d = \left\lceil \sqrt{ \frac{k\log_q k}{2} } \right\rceil,$$
on obtient comme complexité finale :
$$q^{\sqrt{(2+\o(1))k\log_qk}} = L_{q^k}(1/2,\sqrt 2).$$

\subsection{Algorithme de Coppersmith en $L_{Q}(1/3)$}

L'algorithme de Don Coppersmith \cite{coppersmith1984} est plus efficace que l'algorithme de Hellman-Reyneri car il prend une représentation de $\gf{q^k}$ qui facilite la création de relations.

Coppersmith propose de choisir un polynôme irréductible $I_k(X)$ de la forme : $$X^k - S(X),$$ où $S(X) \in \gf{q}[X]$ est un polynôme de degré $d_S$ aussi petit que possible.

Cependant, Cécile Pierrot \cite{pierrot2016} indique divers résultats \cite{joux2006, joux2013} suggérant de choisir $I_k(X)$ comme facteur irréductible de $X^{q^n}-S(X)$. Détaillons : soit $n$ l'unique entier tel que $q^{n-1} < k \leqslant q^n$ et choisissons $S(X)$ de petit degré tel que $X^{q^n}-S(X)$ ait un facteur irréductible de degré $k$. Nous prenons alors ce facteur pour définir notre corps $\gf{q^k}$.

Décomposons $n = n_1 + n_2$ pour des valeurs $n_1$ et $n_2$ que l'on déterminera plus tard. L'idée pour la construction des relations est que pour chaque paire de polynômes $A(X)$ et $B(X)$ de $\gf{q}[X]$, on a l'égalité :
\begin{equation}\label{eqn:coppersmith}
{\left( A(X) + X^{q^{n_1}}B(X)\right)}^{q^{n_2}} = A(X^{q^{n_2}}) + S(X)B(X^{q^{n_2}}) \pmod{I_k(X)},
\end{equation}
grâce à la linéarité de l'élévation à la puissance $q$ (c'est l'automorphisme de Frobenius du corps $\gf{q}$) et à l'égalité $X^{q^n} = S(X) \pmod{I_k(X)}$.

Choisissons un entier $d$ tel que $1 < d < k$. Prenons comme base de friabilité :
$$\mathcal{F} =  \{F(\alpha) : F(X) \in \gf{q}[X] \text{ irréductible unitaire de degré au plus } d \}.$$

L'équation (\ref{eqn:coppersmith}) donne une relation multiplicative nous contentant si les polynômes $A(X) + X^{q^{n_1}}B(X)$ et $A(X^{q^{n_2}}) + S(X)B(X^{q^{n_2}})$ sont $d$-friables, ou de manière équivalente, si le produit :
$$\left( A(X) + X^{q^{n_1}}B(X)\right)\left( A(X^{q^{n_2}}) + S(X)B(X^{q^{n_2}})\right)$$
est $d$-friable. Une fois de plus, nous supposons l'heuristique classique :
\begin{heur}\label{heur:polydfriable}
La probabilité que le produit $$\left( A(X) + X^{q^{n_1}}B(X)\right)\left( A(X^{q^{n_2}}) + S(X)B(X^{q^{n_2}})\right)$$ soit $d$-friable est identique à celle d'un polynôme aléatoire de même degré.
\end{heur}

Nous pouvons étudier les paires de polynômes non-nuls $A(X)$ et $B(X)$ de degré au plus $d$, avec $A(X)$ unitaire (car multiplier par un élément de $\gf{q}$ donne une équation identique). On cherche un couple $(n_1, n_2)$ d'entiers naturels minimisant le degré du produit de l'heuristique~\ref{heur:polydfriable}, i.e. :
$$d + q^{n_1} + d_S + \frac{dq^n}{q^{n_1}}.$$
Il est donc minimisé lorsque $q^{n_1}$ est aussi proche que possible de $\sqrt{dq^n}$. Un tel choix entraîne que le degré asymptotique du polynôme de l'heuristique~\ref{heur:polydfriable} est de l'ordre de $(2+\o(1))\sqrt{dq^n}$, ce qui donne en fonction de $k$, un degré variant entre $(2+\o(1))\sqrt{dk}$ et $(2\sqrt{q}+\o(1))\sqrt{dk}$.
Si $d$ est choisi comme suit :
$$d = (4/3)^{1/3}q^{n/3}n^{2/3},$$
alors la complexité est $L_{q^{q^n}}(1/3, (32/9)^{1/3})$, ce qui donne en fonction de $k$ une complexité variant entre $L_{q^k}(1/3, (32/9)^{1/3})$ et $L_{q^k}(1/3, (32q/9)^{1/3})$.

Chaque relation multiplicative de la forme (\ref{eqn:coppersmith}) donne une équation du type :
$$q^{n_2} \sum_{F(\alpha) \in \mathcal{F}} e_i \log(F(\alpha)) = \sum_{F(\alpha) \in \mathcal{F}} e'_i \log(F(\alpha)) \pmod{q^k-1}.$$
Le système admet plusieurs solutions, et, à l'exception du vecteur nul, n'importe laquelle de celles-ci permet de recouvrer les logarithmes de la base de friabilité. En effet, si l'élément $g$, primitif, est lui-même dans la base $\mathcal{F}$, il est facile de normaliser le vecteur solution pour avoir les logarithmes en base $g$. En revanche, si $g$ n'appartient à $\mathcal{F}$, nous procédons à une phase de logarithme individuel sur $g$ pour déterminer la valeur de la constante de normalisation.

Par ailleurs, comme indiqué par Cécile Pierrot \cite{pierrot2016}, les gros coefficients $q^{n_2}$ ont un impact sur la performance des multiplications, mais dans de bonnes conditions (comme par exemple être en caractéristique 2) et avec un peu de ruse sur les multiplications matrice-vecteur, la phase d'algèbre linéaire n'est pas sensiblement ralentie.

Contrairement à l'algorithme de Hellman-Reyneri, la génération d'une relation faisant intervenir le logarithme d'un élément arbitraire du corps et ceux de la base de friabilité n'est pas si facile dans la méthode de Coppersmith car la base de friabilité est plus petite que pour l'algorithme de Hellman-Reyneri. Aussi apparaît une nouvelle notion essentielle : il s'agit de la \textit{notion de descente}. Ce procédé commence par écrire une relation entre notre élément arbitraire $h = H(\alpha)$ vu comme un polynôme en $\alpha$, l'élément primitif du corps cible $g = G(\alpha)$, et un petit nombre d'autres polynômes auxiliaires de petit degré. En itérant sur les polynômes auxiliaires, il devient alors possible d'exprimer le polynôme initial en produit d'éléments de la base de friabilité $\mathcal{F}$.

Par conséquent, le calcul d'un logarithme discret est maintenant représenté par un arbre dont les fils d'un n\oe ud, qui correspond à un polynôme, sont les n\oe uds des polynômes de plus bas degré apparaissant dans la relation associée. Toutes les feuilles de l'arbre doivent être dans $\mathcal{F}$.

\subsection{Crible par corps de fonctions en $L_Q(1/3)$}

Le crible par corps de fonctions (FFS pour \textit{function field sieve}) est proposé en 1999 par Leonard Adleman et Ming-Deh Huang \cite{adleman1999}. Sans dénaturer l'idée des auteurs, nous présentons l'algorithme en utilisant des anneaux de polynômes et non des corps de fonctions, comme dans \cite{joux2013, joux2006, joux2002, pierrot2016}.

Le point de départ de l'algorithme réside une nouvelle fois dans la manière de définir le corps cible. L'idée consiste à construire l'extension à l'aide de deux relations polynomiales bivariées sur $\gf{q}$ : $$Y = f(X) \quad \text{et}\quad X = g(Y).$$
En assemblant ces deux relations, nous obtenons $X = g(f(X))$. Donc, si le polynôme $g(f(X)) - X$ possède un facteur irréductible $I_k(X)$ de degré $k$, nous pouvons représenter $\gf{q^k}$ à l'aide de celui-ci. Cela constitue notre heuristique :
\begin{heur}
Il existe deux polynômes $f(X)$ et $g(Y)$ de petit degré dans $\gf{q}[X, Y]$ tels que le polynôme $g(f(X)) - X$ possède un facteur irréductible $I_k(X)$ de degré $k$.
\end{heur}
La représentation étant fixée, nous désignons par $\alpha$ l'une des racines dans $\gf{q^k}$ du polynôme $I_k(X)$ et nous posons $\beta = f(\alpha)$. Par construction nous avons $\alpha = g(\beta)$ dans $\gf{q^k}$. À partir de n'importe quelle paire de polynômes $A(X)$ et $B(X)$ univariés de petit degré, nous pouvons écrire :
$$A(\alpha) + f(\alpha)B(\alpha) = A(g(\beta)) + \beta B(g(\beta)).$$
Nous obtenons ainsi une égalité dans $\gf{q^k}$ entre un polynôme en $\alpha$ et un second en $\beta$. De plus, chacun de ces deux polynômes est de degré relativement petit, si les paramètres sont bien choisis. Par conséquent, si chacun d'entre eux se factorise en produits de polynômes irréductibles de degré au plus $d$, nous pouvons exploiter cette relation multiplicative. Soulignons que nous avons ici doublé la taille de la base de friabilité, puisqu'elle contient maintenant l'évaluation de chaque polynôme de la base de friabilité en $\alpha$ et en $\beta$.

Les polynômes $A(X)$ et $B(X)$ sont à choisir de sorte que leur degré soit au plus $d$, tandis le degré de $f(X)$ et $g(Y)$ est choisi, dans~\cite{pierrot2016}, pour vérifier: $$\deg(f(X)) \deg(g(Y)) \approx k \quad\text{et}\quad \frac{\deg(f(X))}{\deg(g(Y))} \approx d.$$
L'optimisation, non détaillée ici mais dans~\cite{pierrot2016}, donne une complexité asymptotique heuristique identique à celle de l'algorithme de Coppersmith:
$$L_{q^k}(1/3, (32/9)^{1/3}).$$

\subsection{Descente special-$\mathfrak{q}$}\label{s-sec:special-q}

La phase de descente décrite par Antoine Joux et Reynald Lercier \cite{joux2006, joux2002} nous servira dans la section suivante. Elle est donnée dans le cadre, et avec les notations, de l'algorithme précédent: le crible par corps de fonctions. Pour rappel, phases de collecte de relations et d'algèbre linéaire sont finies et on souhaite maintenant déterminer le logarithme d'un élément arbitraire $h\in\gf{q^k}$, en l'exprimant à l'aide des éléments de la base de friabilité, que l'on note :
$$\mathcal{F} =  \{F(\gamma) : F(X) \in \gf{q}[X] \text{ irréductible unitaire de degré au plus } d \text{ et } \gamma \in \{\alpha, \beta\}\}.$$

Soient $H(X)\in\gf{q}[X]$ le polynôme tel que $H(\alpha) = h$. Considérons l'ensemble des monômes :
$$\mathcal S_H = \{X^iY^j : 0 \leqslant i \leqslant D_\alpha(H), 0 \leqslant j \leqslant D_\beta(H)\},$$
où $D_\alpha(H)$ et $D_\beta(H)$ sont des paramètres que nous déterminerons plus tard. Chaque monôme dans $\mathcal S_H$ peut être exprimé comme un polynôme univarié en $X$ en substituant $Y$ par $f(X)$. Pour $m(X,Y)$ un monôme de $\mathcal S_H$, notons $V_H(m)(X)$ la valeur modulo $H(X)$ du polynôme univarié correspondant à $m(X,Y)$, i.e.
$$V_H(m)(X) := m(X,f(X)) \pmod{H(X)}.$$
Clairement, $V_H(m)(X)$ peut être représenté par un vecteur $V_H(m)$ à $\deg H(X)$ coefficients dans le corps fini $\gf{q}$. Construisons une matrice $M_H$ dont les colonnes sont les vecteurs $V_H(m)$ pour $m(X,Y) \in \mathcal S_H$. Concrètement, la matrice $M_H$ contient en colonnes des restes de divisions euclidiennes par le polynôme $H(X)$. N'importe quel vecteur du noyau de $M_H$ peut être alors interprété comme combinaison linéaire de ces restes modulo $H(X)$. Ainsi, à chaque vecteur du noyau de $M_H$, on peut associer une combinaison linéaire d'éléments de $\mathcal S_H$, qui est un polynôme $U(X,Y)$, tel que $U(X,f(X))$ est divisible par $H(X)$. Si, à la fois, les polynômes $U(X,f(X))/H(X)$ et $U(g(Y),Y)$ se factorisent en polynômes de degré suffisamment petit, on peut itérer le procédé sur les polynômes de la relation dont le degré est supérieur à $d$.

L'étude faite dans \cite{joux2006, joux2002} et rappelée dans \cite{joux2013}, conseille:
$$D_\alpha(H) D_\beta(H) \geqslant \deg H(X) \quad\text{et}\quad \frac{D_\beta(H)}{D_\alpha(H)} \approx d.$$

\begin{rema}
L'exposé fait ici avec $H(X)\in\gf{q}[X]$ tel que $H(\alpha) = h$, peut aussi être fait avec $H(Y)\in\gf{q}[Y]$ tel que $H(\beta) = h$, en gardant à l'esprit que $X = g(Y)$ et $Y = f(X)$, et en intervertissant les rôles de $D_\alpha$ et $D_\beta$.
\end{rema}
\begin{rema}
Le coût de cette descente augmente lorsque le degré de $H(X)$ diminue.
\end{rema}

\subsection{Algorithme de Joux en $L_{Q}(1/4)$}\label{s-sec:algoJoux}

Nous arrivons enfin à l'algorithme en $L_{Q}(1/4 + \o(1))$ décrit par Antoine Joux. Dans l'article \cite{joux2013}, il commence par rafraichir la mémoire du lecteur sur l'algorithme de Coppersmith et le crible par corps de fonctions. Ensuite il présente prosaïquement les nouvelles idées de son algorithme, suivies par une description plus rigoureuse insistant sur la phase de crible et sur la phase de descente pour le calcul de logarithme individuel. Il conclut par l'étude de la complexité, en faisant remarquer que la phase la plus coûteuse devient la descente. Il clôture son exposé par quelques exemples.

L'un des changements de paradigme majeurs par rapport aux autres algorithmes présentés avant est la construction et non plus la recherche de polynômes friables.

\subsubsection{Présentation des idées de Joux}\label{ss-sec:idees}


\paragraph{Idée 1: les homographies.} Si on a un polynôme qui se factorise, on souhaite lui appliquer une transformation afin d'obtenir d'autres polynômes qui se factorisent eux aussi. Pour cela, on considère la transformation induite par les homographies, à savoir :
$$X \mapsto \frac{aX+b}{cX+d}.$$
Cependant, faire ce changement de variable ne donne pas un polynôme : si $f(X) \in\gf{q}[X]$ est un polynôme, ce n'est pas forcement le cas de $f((aX+b)/(cX+d))$. Ainsi, nous considérons plutôt l'évaluation homogène d'un polynôme, i.e. pour un polynôme $f(X)$ de $\gf{q}[X]$, dont on note $\deg f$ le degré, on considère le polynôme :
$$F_{a,b,c,d}(X) := (cX+d)^{\deg f} f \left(\frac{aX+b}{cX+d}\right).$$
Formalisons cela en le théorème suivant :
\begin{theo}
Soient $f(X) \in \gf{q}[X]$ un polynôme unitaire et $\gf{q^k}$ une extension de $\gf{q}$. Soit $(a,b,c,d) \in \gf{q^k}^4$ tel que $ad \neq bc$ et considérons le polynôme :
$$F_{a,b,c,d}(X) := (cX+d)^{\deg f} f \left(\frac{aX+b}{cX+d}\right).$$
Si le polynôme $f(X)$ admet la factorisation en produit de polynômes irréductibles unitaires : $$f(X) = \prod_{i=1}^k F_i(X)^{e_i},$$
alors le polynôme $F_{a,b,c,d}(X)$ admet la factorisation suivant :
$$F_{a,b,c,d}(X) = \prod_{i=1}^k {\left( (cX+d)^{\deg F_i} F_i\left(\frac{aX+b}{cX+d}\right)\right)}^{e_i}.$$
Remarquons que les facteurs de cette décomposition ne sont pas nécessairement unitaires, ni irréductibles, et qu'ils peuvent avoir un degré plus petit que le facteur correspondant.
\end{theo}
\begin{proof}
La factorisation induite est claire : il suffit de faire le changement de variable de chaque côté et de remarquer que les termes
$$(cX+d)^{\deg F_i} F_i\left(\frac{aX+b}{cX+d}\right)$$
sont en effet des polynômes. Visiblement, il n'y a aucune raison pour que les facteurs ainsi transformés soient irréductibles dans $\gf{q^k}[X]$. Remarquons que lorsque $c \neq 0$, le coefficient de $X^{\deg{F_i}}$ venant de $F_i$ est $c^{\deg F_i}F_i(a/c)$. Comme il n'est pas nécessairement égal à $1$ et peut même être nul, on observe que les facteurs transformés ne sont pas nécessairement unitaires et peuvent être de degré strictement inférieur à celui du $F_i(X)$ correspondant.
\end{proof}

\paragraph{Idée 2: un polynôme toujours scindé.} La seconde idée découle directement de la première. Comme on sait faire plusieurs \og{}copies\fg{} d'un polynôme, on souhaite considérer un polynôme qui se factorise agréablement. Sur $\gf{q}$, un candidat naturel est : $$X^q -X = \prod_{\gamma\in\gf{q}} X-\gamma.$$

\paragraph{Idée 3: une bonne représentation du corps.} L'image de $X^q-X$ par une homographie est un polynôme combinaison linéaire des monômes $X^{q+1}$, $X^q$, $X$ et $1$. Pour obtenir une relation multiplicative, on désire donc trouver une représentation du corps fini qui transforme le polynôme $X^q$ en un polynôme de bas degré. Une façon de faire est de demander la satisfaction dans $\gf{q^k}$ de la relation :
$$x^q = \frac{h_0(x)}{h_1(x)}.$$
Cela défini le corps $\gf{q^k}$ si, et seulement si, le polynôme $h_1(X)X^q - h_0(X)$ admet un facteur irréductible $I_k(X)$ de degré $k$, et alors $x = X \pmod{I_k(X)}$ vérifie bien la relation demandée.

\subsubsection{Description de l'algorithme}

L'algorithme de Joux combine les idées précédentes pour calculer des logarithmes discrets dans des corps de petite caractéristique. La description laisse de côté l'étude de la phase d'algèbre linéaire: une fois de plus, le lecteur est invité à consulter les travaux de Don Coppersmith, Andrew Odlyzko, et Richard Schroeppel \cite{coppersmith1986} et de Douglas Wiedemann \cite{wiedemann1986}.

\paragraph{Choix des paramètres.}Étant donné un corps $\gf{p^n}$ de petite caractéristique, nous commençons par l'imbriquer dans un corps de la forme $\gf{q^{2k}}$, avec $k \leqslant q$. Cela se fait, par exemple, en prenant une extension de degré $e$ de $\gf{p^n}$, où $e \leqslant 2 \ceil{\log_p n}$.

Ensuite, le corps fini $\gf{q^{2k}}$ est construit comme une extension de degré $k$ de $\gf{q^2}$. Plus précisément, nous appliquons la troisième idée du paragraphe~\ref{ss-sec:idees} : on choisit deux polynômes $h_0(X)$ et $h_1(X)$ de $\gf{q^2}[X]$ de bas degré de sorte que $h_1(X)X^q - h_0(X)$ ait un facteur irréductible $I_k(X)$ de degré $k$.
\begin{heur}
Quel que soit le degré de l'extension $k$, on peut trouver $h_0(X)$ et $h_1(X)$  tel que $h_1(X)X^q - h_0(X)$ ait un facteur irréductible de degré $k$.
\end{heur}
Et en fait, Antoine Joux \cite{joux2013} indique que nous pouvons même nous limiter aux polynômes de degré 2, et espérer malgré tout avoir une bonne représentation de notre corps.

\paragraph{Logarithmes des polynômes linéaires.}Nous voulons déterminer les logarithmes de tous les polynômes linéaires de notre corps. Pour cela, nous construisons des relations multiplicatives entre de tels éléments, en utilisant la première et la seconde idées du paragraphe~\ref{ss-sec:idees}.

Pour générer de telles relations, partons de l'identité polynomiale:
\begin{equation}\label{eqn:identitySplit}
\prod_{\gamma\in\gf{q}} (X-\gamma) = X^q-X,
\end{equation}
et appliquons la transformation homographique $X \mapsto (aX+b)/(cX+d)$, où $(a,b,c,d)\in\gf{q^2}^4$ satisfait à $ad\neq bc$, puis multiplions par $(cX+d)^{q+1}$, ce qui donne d'une part, en prenant seulement le membre de gauche de l'équation~\ref{eqn:identitySplit} :
\begin{align*}
(cX+d)^{q+1} \prod_{\gamma\in\gf{q}} \left(\frac{aX+b}{cX+d}-\gamma\right) &= (cX+d) \prod_{\gamma\in\gf{q}} (aX+b-\gamma(cX+d)), \\
&= (cX+d) \prod_{\gamma\in\gf{q}} ((a-\gamma c)X+b-\gamma d),\\
\end{align*}
et d'autre part, en considérant uniquement le membre de droite :
\begin{align*}
(cX+d)^{q+1}\left({\left(\frac{aX+b}{cX+d}\right)}^q - \frac{aX+b}{cX+d}\right) &= (aX+b)^q(cX+d) - (aX+b)(cX+d)^q. \\
\end{align*}
D'où enfin :
$$(cX+d) \prod_{\gamma\in\gf{q}}((a-\gamma c)X + (b-\gamma d)) = (aX+b)^q(cX+d) - (aX+b)(cX+d)^q.$$
Développons le membre de droite de cette dernière équation et réduisons modulo $I_k(X)$ :
$$a^qcX^{q+1} + a^qdX^q + b^qcX + b^qd - ac^qX^{q+1} - ad^qX - bc^qX^q - bd^q$$
$$= (a^qc - ac^q)X^{q+1} + (a^qd - bc^q)X^q + (b^qc - ad^q)X + b^qd - bd^q,$$
$$\equiv (a^qc - ac^q)X\frac{h_0(X)}{h_1(X)} + (a^qd - bc^q)\frac{h_0(X)}{h_1(X)} + (b^qc - ad^q)X + b^qd - bd^q \pmod{I_k(X)}.$$
Cela nous donne l'égalité, modulo $I_k(X)$, suivante:
$$(a^qc - ac^q)Xh_0(X) + (a^qd - bc^q)h_0(X) + (b^qc - ad^q)Xh_1(X) + (b^qd - bd^q)h_1(X)$$
$$= h_1(X)(cX+d) \prod_{\gamma\in\gf{q}}((a-\gamma c)X + (b-\gamma d)).$$
Par conséquence, nous obtenons une égalité dans $\gf{q^2}[X]/(I_k(X)) \cong \gf{q^{2k}}$ entre un produit de polynômes linéaires et $h_1(X)$ d'une part et un polynôme de bas degré d'autre part. En ajoutant $h_1(X)$ à la base de friabilité, nous obtenons une relation satisfaisante dès que le membre de gauche se factorise en polynômes linéaires.

\paragraph{Comptage des relations.}Le procédé ci-dessus génère une relation candidate pour chaque quadruplet $(a,b,c,d) \in \gf{q^2}^4$. Cependant, certaines de ces relations sont générées plusieurs fois, avec des $(a,b,c,d)\in\gf{q^2}^4$ distincts. Par exemple, si $(a,b,c,d)\in\gf{q}^4$, nous obtenons une équation triviale.

Pour cette raison, Joux \cite{joux2013} préconise de prendre les coefficients $a,b,c,d$ dans $\gf{q^2}$. En étudiant l'action de $\operatorname{PGL}_2(\gf{q^2})$ sur la droite projective $\mathbb{P}_1(\gf{q})$ et du fait que $\operatorname{PGL}_2(\gf{q})$ laisse $\mathbb{P}_1(\gf{q})$ globalement invariant, Joux déduit le nombre d'équations candidates :
$$\frac{q^6 - q^2}{q^3 - q} = q^3 + q.$$
Après un argument heuristique, Joux \cite{joux2013} explique qu'il suffit de considérer $\O(q^2)$ quadruplets, en évitant ceux donnant des duplicatas, pour pouvoir passer à la phase d'algèbre linéaire sur les logarithmes des polynômes linéaires.

\paragraph{Étendre la base aux polynômes de degré $2$.} Si nous appliquons la même stratégie que précédemment, nous ne pourrions pas compléter la base de friabilité avec tous les polynômes irréductibles de degré $2$. En effet, on pourrait garder les relations comprenant à la fois des polynômes de degré $1$ et de degré $2$. Mais, étant donné qu'il y a $\O(q^4)$ polynômes irréductibles de degré $2$ à coefficients dans $\gf{q^2}$ et qu'on ne peut fabriquer que $\O(q^3)$ relations par la méthode précédente, il serait impossible de recouvrer le logarithme de tous les polynômes irréductibles de degré $2$.

Une stratégie qui fonctionne est d'accomplir la transformation suivante :
$$X \mapsto \frac{a(X^2+\theta X) + b}{c(X^2 + \theta X) +d},$$
pour $\theta \in \gf{q^2}$ et $(a,b,c,d) \in \gf{q^2}^4$. Ce que Joux \cite{joux2013} fait ici est qu'il partitionne l'ensemble des polynômes de degré $2$ en plusieurs sous-ensembles, indexés par $\theta$. Après ce changement dans l'équation~\ref{eqn:identitySplit}, on multiplie l'égalité par $\left(c(X^2+\theta X) +d\right)^{q+1}$ et le membre de gauche se factorise en  produit d'une constante de $\gf{q^2}$ et de polynômes irréductibles de degré $2$ ayant la forme $X^2 + \theta X + \kappa \in \gf{q^2}[X]$. Si nous gardons seulement les relations où le membre de droite se factorise en polynômes linéaires, nous pouvons déterminer les logarithmes des polynômes $X^2 +\theta X + \kappa$ irréductibles, où $\theta$ est fixé. Cela nous fait résoudre $q^2$ systèmes (un pour chaque $\theta$) de taille $\O(q^2)$ chacun.

\paragraph{Phase 0.}Soit l'élément $h$ dont nous souhaitons déterminer le logarithme, $h = H(\alpha)$ est écrit comme un polynôme de degré au plus $k-1$ sur $\gf{q^2}$, où $\alpha$ est une racine fixée de $I_k(X)$ et $H(X)$ est un polynôme de $\gf{q^2}[X]$.

\paragraph{Phase 1: descente special-$\mathfrak{q}$.}La première phase de descente fait appel à la descente special-$\mathfrak{q}$, déjà exposée au paragraphe~\ref{s-sec:special-q}. Cependant, nous ne possédons pas de seconde indéterminée $Y$. Il faut donc créer $Y$ en fonction de $X$. Joux \cite{joux2013} précise que la méthode que nous nous apprêtons à exposer ne marche que dans le cas d'un corps de petite caractéristique.

Notons $p$ la caractéristique du corps fini, soit $\ell$ tel que $q = p^\ell$ et posons $r := \floor{\ell/2}$. Si $Y = X^{p^{r}}$ alors, par définition de notre corps:
$$Y^{qp^{-r}} = X^q = \frac{h_0(X)}{h_1(X)}.$$
Si $h_0(X)$ ou $h_1(X)$ est de degré $2$ ou plus, il faut recourir à un légère variation par rapport à la descente special-$\mathfrak{q}$. À savoir, là où dans \ref{s-sec:special-q} on considérait une relation de la forme $U(X,f(X)) = U(g(Y),Y)$, on considère ici la relation:
$${\left({U(X,X^{p^r})}\right)}^{qp^{-r}} = U'\left( X^{qp^{-r}},\frac{h_0(X)}{h_1(X)}\right),$$
où $U'(X,Y) \in \gf{q^2}[X,Y]$ est obtenu à partir de $U(X,Y)\in \gf{q^2}[X,Y]$ en élevant ses coefficients à la puissance $qp^{-r}$.

Comme cette méthode est coûteuse si nous souhaitons atteindre les éléments de la base de friabilité, Antoine Joux \cite{joux2013} introduit une nouvelle méthode à employer lorsque nous avons affaire à des polynômes de degré bas, mais pas encore dans la base de friabilité.

\paragraph{Phase 2: descente basée sur un système bilinéaire.}L'idée de cette descente qui vient compléter la descente classique précédente est: étant donné un polynôme $H(X)$, nous cherchons une paire de polynômes de bas degré, $k_1(X)$ et $k_2(X)$, de $\gf{q^2}[X]$, tels que $H(X)$ divise la différence $(k_1(X)^qk_2(X)-k_1(X)k_2(X)^q) \pmod{I_k(X)}$. Ainsi, la relation:
$$(k_1(X)^qk_2(X)-k_1(X)k_2(X)^q) \equiv (k_1(X)^qk_2(X)-k_1(X)k_2(X)^q) \quad (\operatorname{rem}I_k(X)).$$
a un facteur égal à $H(X)$ dans le membre de droite et le membre de gauche se factorise en polynômes de degré au plus $D$. Comme le degré total du membre de droite est majoré par un petit multiple de $D$ (lié au degré de $h_0$ et $h_1$), avec un bonne probabilité, nous obtenons une relation polynomiale entre $H(X)$ et des polynômes de degré au plus $D$.

Reste à construire de tels polynômes $k_1(X)$ et $k_2(X)$. Antoine Joux \cite{joux2013} remarque que la condition $(k_1(X)^qk_2(X)-k_1(X)k_2(X)^q) \pmod{I_k(X)}$ s'annule modulo $H(X)$ se réécrit comme un système d'équations multivariées sur $\gf{q}$, qui peut être efficacement résolue par des méthodes de résolutions à l'aide de bases de Gröbner.
Ce système est même bilinéaire en $k_1(X)$ et $k_2(X)$ puisque chaque monôme qui apparaît dans le système contient au plus une inconnue provenant de $k_1(X)$ et une de $k_2(X)$.

Plus précisément, considérons chaque coefficient de $k_1(X)$ et $k_2(X)$ comme une indéterminée appartenant au corps des coefficients $\gf{q^2}$. Si $x$ est une telle inconnue, nous l'écrivons $x_0 + zx_1$, où $(1,z)$ est une base de $\gf{q^2}$ sur $\gf{q}$, et $x_0$ et $x_1$ sont des inconnues appartenant à $\gf{q}$. Avec une telle convention: $$x^q = x_0 + z^qx_1.$$
Le système a $\deg H(X)$ équations sur $\gf{q^2}$ et peut s'écrire comme un système à $2\deg H(X)$ équations sur $\gf{q}$. En supposant que $k_1(X)$ est unitaire, le nombre maximum d'inconnues est $2(\deg k_1(X) + \deg k_2(X) + 1)$. Cependant, à cause de l'action de $\operatorname{PGL}_2(\gf{q})$, plusieurs couples $(k_1(X),k_2(X))$ distincts donnent le même polynôme $(k_1(X)^qk_2(X)-k_1(X)k_2(X)^q)$. Pour éviter cela, il faut fixer au moins une inconnue dans $\gf{q^2} \setminus \gf{q}$, laissant ainsi le choix de $2(\deg k_1(X) + \deg k_2(X))$ inconnues dans $\gf{q}$.

Antoine Joux \cite{joux2013} fait ensuite un raisonnement heuristique cherchant à déterminer sous quelles conditions le système précédent admet une solution avec une bonne probabilité, à savoir: nous avons besoin que
$$\deg k_1(X) + \deg k_2(X) \geqslant \deg H(X) + 1.$$
Enfin, il étudie la complexité de cette descente. Pour cela, il s'appuie sur les travaux de Jean-Charles Faugère, Mohab Safey El Din et Pierre-Jean Spaenlehauer, dont le résultat principal dans \cite{faugere2011, spaenlehauer2012} donne que la complexité est exponentielle en $\min(\deg k_1(X), \deg k_2 (X))$.
Plus précisément, en posant $d = \deg k_2(X)$ et donc $\deg k_1(X) = \deg H(X) +1 - d$, la complexité est :
$$\binom{2 (\deg H(X)) + 3}{2d+1}^\omega,$$
où $2 \leqslant \omega \leqslant 3$ est l'exposant de l'algèbre linéaire.
Le choix de $d$ est donné dans la section suivante.

\subsubsection{Analyse de la complexité}

Nous présentons succinctement l'analyse de la complexité faite par Antoine Joux pour son algorithme \cite{joux2013}. Nous nous contentons d'un survol car l'algorithme de Razvan Barbulescu, Pierrick Gaudry, Antoine Joux et Emmanuel Thomé \cite{barbulescu2013}, publié aussi en 2013, atteint une complexité théorique qui est quasi-polynomiale.

Le changement de représentation et la phase de crible se font en temps polynomial. La phase d'algèbre linéaire s'effectue en $\O(q^7)$ opérations arithmétiques.

Pour étudier la complexité de la phase de descente, écrivons $k = \alpha q$, pour une constante $\alpha \leqslant 1 + \deg(h_1(X)) / q$. Sous cette hypothèse, nous remarquons:
$$L_{q^{2k}}(\beta, c) \approx \exp\left((c'+\o(1))q^\beta\log(q)\right),\quad\text{où } c' = c(2\alpha)^\beta.$$
Comme le coût de la descente special-$\mathfrak{q}$ augmente quand le degré du polynôme cible diminue, on utilise cette méthode jusqu'à atteindre des polynômes de degré $\O(\sqrt{q})$, plus précisément de degré $c_c\sqrt{q/\log q}$, pour une constante $c_c$. Le coût de cette descente dans ce cas est:
$$\exp\left(\frac{1}{2\mu}\sqrt{\frac{\alpha}{c_c}}q^{1/4}(\log q)^{5/4}\right),$$
où $\mu < 1$. Pour ce qui est de la nouvelle descente, Joux fait en sorte de choisir le paramètre $d$ pour que le coût soit dominé par les polynômes de degré $c_c\sqrt{q/\log q}$. Ce qui l'amène à choisir
$$d = \ceil{\left(\frac{c_c}{6}\sqrt{q\log q}\right)^{1/2}}.$$
Cela donne, pour cette phase, un coût de:
$$\exp\left(\left( \frac{\sqrt{6c_c}}{4} + \o(1)\right)q^{1/4}(\log q)^{5/4}\right).$$
Pour que le coût des deux phases de descente s'équilibre, il prend:
$$c_c = \frac{1}{\mu}\sqrt{\frac{2\alpha}{3}},$$
ce qui atteint la complexité:
$$\exp\left(\left(\frac{1}{2\sqrt{\mu}}{\left(\frac{3\alpha}{2}\right)}^{1/4}+\o(1)\right)q^{1/4}(\log q)^{5/4}\right),$$
qui peut être réécrit comme $L(1/4+\o(1))$.

\section{Les conséquences pour le cryptosystème de Chor-Rivest}\label{sec:consequences}

Après avoir pris connaissance du fonctionnement du cryptosystème de Chor-Rivest~\cite{chorRivest1988} en section~\ref{sec:cryptosysteme} et de la cryptanalyse de Serge Vaudenay~\cite{vaudenay2000} en section~\ref{sec:cryptanalyse}, nous souhaitons appliquer ses recommandations, i.e. prendre $p$ et $h$ premiers et ne pas diffuser tous les éléments de la clé publique.

\subsection{Résultats de chercheurs de Madrid et Salamanque}
Une étude a été faite par Luis Hern\'andez Encinas, Jaime Mu\~noz Masqué et Araceli Queiruga Dios en 2008~\cite{HEMMQD2008}, puis en 2009~\cite{HEMMQD2009}.
Dans l'article~\cite{HEMMQD2008}, les auteurs donnent un seul jeu de paramètres $(p,h)$ qu'ils jugent utilisable: $(409,17)$. Mais ils indiquent que se limiter à l'unique corps $\gf{409^{17}}$ est trop restrictif et menace la sécurité du système.
Dans leur second article~\cite{HEMMQD2009}, ils traitent aussi le cas où $h$ est un carré de nombre premier, puisque, si $h$ est un nombre premier ou un carré de nombre premier, alors il ne possède pas de diviseur $r$ tel que $r \geqslant \sqrt{h + 1/4} + 1/2$, et c'est une condition qui rend possible la cryptanalyse de Vaudenay. Ils arrivent donc à divers jeux de paramètres $(p,h)$, qu'ils trient en fonction de la friabilité de $p^h-1$, de la taille de la clé produite et de la densité du cryptosystème. Ils se restreignent ensuite à une dizaine de jeux de paramètres pour lesquels la clé publique est obtenue en moins d'une journée de calculs. Enfin, pour ces paramètres, ils finissent en étudiant les temps de chiffrement et de déchiffrement en fonction du pourcentage de clé publique diffusée: 50\%, 25\% et 10\%.

\paragraph{Taille de la clé publique.}Étant donné que la clé publique est constituée de $p$ entiers compris entre $0$ et $p^h -1$, la taille de la clé publique est:
$$p \log_2(p^h-1) \approx hp\log_2(p).$$
Par exemple, pour les paramètres $(p,h) = (197, 24)$, la taille de la clé publique est de $36\;038$ bits, soit environ 4.5 Ko.

\paragraph{Densité du sac à dos.}Comme indiqué au début de la section~\ref{sec:cryptosysteme}, le cryptosystème de Chor-Rivest résiste à l'attaque de Lagarias-Odlyzko\cite{lagarias1983} sur les sac à dos de faible densité. En appliquant la définition de densité, nous obtenons la densité du cryptosystème:
$$\frac{p}{\log_2(p^h-1)}.$$
Depuis la publication de~\cite{lagarias1983} et d'autres résultats qui ont suivi, les sacs à dos de densité $< 1$ sont vulnérables à cette attaque.
Par exemple, pour les paramètres $(p,h) = (197, 24)$, la densité du cryptosystème est 1,077.

\paragraph{Calcul des logarithmes.}Pour calculer les logarithmes dans le corps $\gf{p^h}$, Luis Hern\'andez Encinas, Jaime Mu\~noz Masqué et Araceli Queiruga Dios ont recourt à l'algorithme de Pohlig-Hellman avec pas de bébé -- pas de géant, et qui, d'après le théorème~\ref{theo:pohligHellman}, a une complexité en:
$$\O\left(\log(p^h-1)^2 + \frac{\sqrt{B}\log(p^h-1)}{\log(B)}\right),$$
où $B$ est le plus grand facteur premier de $p^h-1$.

\subsection{Comparaison des deux algorithmes}

Nous avons implanté l'algorithme de Pohlig-Hellman\footnote{Consulter le fichier \textit{pohlig-hellman.sage}}, avec l'algorithme pas de bébé--pas de géant.
Il fonctionne aussi avec les extensions explicites de corps, i.e. lorsque l'on utilise la méthode \verb|.quotient_ring()| en SageMath.

D'autre part, nous avons aussi implanté certaines étapes de l'algorithme d'Antoine Joux: les phases de collecte de relations entre polynômes linéaires et d'algèbre linéaire.
Le choix de la méthode pour résoudre le système linéaire est laissé à SageMath, qui a priori connaît des méthodes de calculs sur les matrices creuses, via l'argument \verb|sparse=True|.

Nous avons comparé nos algorithmes sur des petits corps, comme $\gf{5^3}$. Là où l'algorithme de Pohlig-Hellman calcule relativement rapidement, de l'ordre de la demi seconde, un logarithme discret,
l'algorithme de Joux prend du temps à changer de représentation, à collecter les relations, puis à résoudre le système linéaire, le tout mettant environ une vingtaine de minutes pour avoir les logarithmes de la base de friabilitré. De plus, le système linéaire obtenu n'a pas tout le temps eu
un noyau trivial.

Nous pensons que l'échec de l'algorithme Joux est dû au fait que le corps choisi est très petit, et nous n'avons pas eu le temps de conduire d'autres expériences, bien que nous pensons que pour nos logarithmes, on peut se contenter de l'algorithme de Pohlig-Hellman.

\section*{Conclusion}

Nous avons presenté dans ce rapport le cryptosystème de Chor-Rivest, ainsi que la meilleure
attaque connue à ce jour sur celui-ci: la cryptanalyse de Serge Vaudenay.
Les conclusions de Vaudenay préconisent de choisir de $p$ et $h$ premiers, ce qui rend le calcul de logarithme
discret dans $\gf{p^h}$ difficile. Pour cela, nous avons pensé utiliser l'algorithme d'Antoine Joux.
Cependant, les logarithmes que nous cherchons à déterminer ne sont pas aussi ardus que ceux de Joux, et il semble que, dans notre cas, nous pouvons nous contenter
d'algorithmes tels que Pohlig-Hellman et rho de Pollard.

En revanche, on peut se demander s'il existe une façon de n'avoir recours qu'aux phases de collecte de relations et d'algèbre linéaire de l'algorithme d'Antoine Joux,
sans que cela ne menace la sécurité du système. Ou encore, est-il possible de combiner Pohlig-Hellman avec l'algorithme de Joux? Cela paraît peu probable, même si nous ne pouvons l'affirmer.
Enfin, on peut se poser la question de la resistance du cryptosystème si on se place dans un corps comme $\gf{p^h}$ avec $h$ premier et $p$ une puissance première de $2$, ainsi que
de l'efficacité de l'algorithme de Joux dans ce cas particulier.

\newpage
\thispagestyle{empty}
\bibliographystyle{abbrv}
\bibliography{mybib}

\end{document}
